---
layout: post
title: 'æ·±åº¦è§£æï¼šåˆ†å¸ƒå¼ç³»ç»Ÿå„ç»„ä»¶'
subtitle: 'åˆ†å¸ƒå¼ é›†ç¾¤ åä½œ'
date: 2025-12-24
categories: åˆ†å¸ƒå¼ç³»ç»Ÿ æ¶æ„
cover: ''
tags: åˆ†å¸ƒå¼ç³»ç»Ÿ
toc: true
mermaid: true  # Force Mermaid loading
---



## ä¸€ã€æœåŠ¡é›†ç¾¤æ·±å…¥è§£æ

### 1. ä»€ä¹ˆæ˜¯é›†ç¾¤ï¼Ÿ

**å½¢è±¡æ¯”å–»**ï¼š
```
å•æœº = ä¸€ä¸ªå¨å¸ˆåšèœ
      å®¢äººå¤šäº† â†’ å¨å¸ˆç´¯æ­» â†’ ä¸Šèœæ…¢ â†’ å¨å¸ˆç”Ÿç—…é¤å…å…³é—¨

é›†ç¾¤ = ä¸‰ä¸ªå¨å¸ˆåšèœ
      å®¢äººå¤šäº† â†’ åˆ†é…ç»™ä¸åŒå¨å¸ˆ â†’ é€Ÿåº¦å¿« â†’ ä¸€ä¸ªå¨å¸ˆç”Ÿç—…å…¶ä»–äººé¡¶ä¸Š
```

### 2. é›†ç¾¤å¦‚ä½•å·¥ä½œï¼Ÿ

#### **è´Ÿè½½å‡è¡¡ç­–ç•¥**

```mermaid
graph TB
    Client[å®¢æˆ·ç«¯è¯·æ±‚]
    LB[è´Ÿè½½å‡è¡¡å™¨]
    
    subgraph "JavaæœåŠ¡é›†ç¾¤"
        S1[æœåŠ¡å™¨1<br/>192.168.1.10:8080<br/>å½“å‰è´Ÿè½½:  30%]
        S2[æœåŠ¡å™¨2<br/>192.168.1.11:8080<br/>å½“å‰è´Ÿè½½:  50%]
        S3[æœåŠ¡å™¨3<br/>192.168.1.12:8080<br/>å½“å‰è´Ÿè½½:  20%]
    end
    
    Client --> LB
    
    LB -->|è½®è¯¢ç®—æ³•| S1
    LB -->|è½®è¯¢ç®—æ³•| S2
    LB -->|è½®è¯¢ç®—æ³•| S3
    
    style S1 fill:#c8e6c9
    style S2 fill:#fff9c4
    style S3 fill:#c8e6c9
```

**å¸¸è§è´Ÿè½½å‡è¡¡ç®—æ³•**ï¼š

```java
// 1. è½®è¯¢ï¼ˆRound Robinï¼‰- æœ€ç®€å•
è¯·æ±‚1 â†’ æœåŠ¡å™¨1
è¯·æ±‚2 â†’ æœåŠ¡å™¨2
è¯·æ±‚3 â†’ æœåŠ¡å™¨3
è¯·æ±‚4 â†’ æœåŠ¡å™¨1  // å¾ªç¯
è¯·æ±‚5 â†’ æœåŠ¡å™¨2

// 2. åŠ æƒè½®è¯¢ï¼ˆWeighted Round Robinï¼‰
æœåŠ¡å™¨1ï¼šæƒé‡3ï¼ˆæ€§èƒ½å¥½ï¼‰
æœåŠ¡å™¨2ï¼šæƒé‡2ï¼ˆæ€§èƒ½ä¸­ç­‰ï¼‰
æœåŠ¡å™¨3ï¼šæƒé‡1ï¼ˆæ€§èƒ½å·®ï¼‰

10ä¸ªè¯·æ±‚çš„åˆ†é…ï¼š
æœåŠ¡å™¨1å¤„ç†5ä¸ª
æœåŠ¡å™¨2å¤„ç†3ä¸ª
æœåŠ¡å™¨3å¤„ç†2ä¸ª

// 3. æœ€å°‘è¿æ¥ï¼ˆLeast Connectionsï¼‰
æœåŠ¡å™¨1ï¼šå½“å‰10ä¸ªè¿æ¥
æœåŠ¡å™¨2ï¼šå½“å‰5ä¸ªè¿æ¥  â† æ–°è¯·æ±‚ç»™å®ƒ
æœåŠ¡å™¨3ï¼šå½“å‰8ä¸ªè¿æ¥

// 4. IPå“ˆå¸Œï¼ˆIP Hashï¼‰
ç”¨æˆ·IP:  192.168.1.100 â†’ hash â†’ æ°¸è¿œåˆ†é…åˆ°æœåŠ¡å™¨2
å¥½å¤„ï¼šåŒä¸€ç”¨æˆ·æ€»æ˜¯è®¿é—®åŒä¸€å°æœåŠ¡å™¨ï¼ˆä¼šè¯ä¿æŒï¼‰
```

#### **å®é™…é…ç½®ç¤ºä¾‹ï¼ˆNginxï¼‰**

```nginx
# nginx.conf
upstream java_backend {
    # åŠ æƒè½®è¯¢
    server 192.168.1.10:8080 weight=3;
    server 192.168.1.11:8080 weight=2;
    server 192.168.1.12:8080 weight=1;
    
    # å¥åº·æ£€æŸ¥ï¼š3ç§’å†…å¤±è´¥2æ¬¡ï¼Œè¸¢å‡º30ç§’
    server 192.168.1.10:8080 max_fails=2 fail_timeout=30s;
}

server {
    listen 80;
    
    location / {
        proxy_pass http://java_backend;
        
        # ä¼ é€’çœŸå®IP
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

### 3. é›†ç¾¤çš„ä¼šè¯é—®é¢˜

**é—®é¢˜åœºæ™¯**ï¼š
```
ç”¨æˆ·ç™»å½• â†’ è´Ÿè½½åˆ°æœåŠ¡å™¨1 â†’ Sessionå­˜åœ¨æœåŠ¡å™¨1çš„å†…å­˜
ç”¨æˆ·åˆ·æ–° â†’ è´Ÿè½½åˆ°æœåŠ¡å™¨2 â†’ æœåŠ¡å™¨2æ²¡æœ‰Session â†’ è¦æ±‚é‡æ–°ç™»å½• âŒ
```

**è§£å†³æ–¹æ¡ˆï¼šSessionå…±äº«**

```mermaid
graph LR
    User[ç”¨æˆ·]
    S1[æœåŠ¡å™¨1]
    S2[æœåŠ¡å™¨2]
    S3[æœåŠ¡å™¨3]
    Redis[(Redis<br/>ç»Ÿä¸€Sessionå­˜å‚¨)]
    
    User -->|ç™»å½•| S1
    S1 -->|å­˜Session| Redis
    
    User -->|åˆ·æ–°| S2
    S2 -->|è¯»Session| Redis
    Redis -->|è¿”å›Session| S2
    S2 -->|å·²ç™»å½•çŠ¶æ€| User
    
    style Redis fill:#ffebee
```

**ä»£ç å®ç°**ï¼š

```java
// Spring Booté…ç½®Redis Session
@Configuration
@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 1800) // 30åˆ†é’Ÿ
public class SessionConfig {
    // è‡ªåŠ¨é…ç½®ï¼ŒSessionä¼šå­˜åˆ°Redis
}

// ä½¿ç”¨æ—¶å®Œå…¨é€æ˜
@RestController
public class UserController {
    
    @PostMapping("/login")
    public Result login(HttpSession session, String username, String password) {
        // éªŒè¯ç”¨æˆ·åå¯†ç ... 
        User user = userService.login(username, password);
        
        // å­˜å…¥Sessionï¼ˆè‡ªåŠ¨å­˜åˆ°Redisï¼‰
        session.setAttribute("user", user);
        
        return Result.success();
    }
    
    @GetMapping("/profile")
    public Result getProfile(HttpSession session) {
        // ä»Sessionè·å–ï¼ˆè‡ªåŠ¨ä»Redisè¯»ï¼‰
        User user = (User) session.getAttribute("user");
        
        if (user == null) {
            return Result. error("æœªç™»å½•");
        }
        
        return Result.success(user);
    }
}
```

**Redisä¸­çš„å­˜å‚¨ç»“æ„**ï¼š
```
Key: spring:session:sessions:a1b2c3d4-e5f6-7890
Value: {
    "sessionAttr: user": {
        "id": 123,
        "username": "zhangsan",
        "loginTime": "2025-12-24 10:00:00"
    }
}
TTL: 1800ç§’
```

---

## äºŒã€Kafka æ¶ˆæ¯é˜Ÿåˆ—æ·±åº¦è§£æ

### 1. **æ ¸å¿ƒæ¦‚å¿µ**

#### ğŸ“¦ åŸºæœ¬ç»„æˆéƒ¨åˆ†

```mermaid
graph LR
    subgraph "Kafkaé›†ç¾¤"
        B1[Broker 1<br/>æœåŠ¡å™¨1]
        B2[Broker 2<br/>æœåŠ¡å™¨2]
        B3[Broker 3<br/>æœåŠ¡å™¨3]
    end
    
    subgraph "Topic:  è®¢å•ä¸»é¢˜"
        P0[Partition 0<br/>åˆ†åŒº0]
        P1[Partition 1<br/>åˆ†åŒº1]
        P2[Partition 2<br/>åˆ†åŒº2]
    end
    
    Producer[ç”Ÿäº§è€…<br/>è®¢å•æœåŠ¡] -->|å‘é€æ¶ˆæ¯| P0
    Producer -->|å‘é€æ¶ˆæ¯| P1
    Producer -->|å‘é€æ¶ˆæ¯| P2
    
    P0 -->|æ¶ˆè´¹æ¶ˆæ¯| C1[æ¶ˆè´¹è€…1<br/>åº“å­˜æœåŠ¡]
    P1 -->|æ¶ˆè´¹æ¶ˆæ¯| C1
    P2 -->|æ¶ˆè´¹æ¶ˆæ¯| C1
    
    P0 -->|æ¶ˆè´¹æ¶ˆæ¯| C2[æ¶ˆè´¹è€…2<br/>ç§¯åˆ†æœåŠ¡]
    P1 -->|æ¶ˆè´¹æ¶ˆæ¯| C2
    P2 -->|æ¶ˆè´¹æ¶ˆæ¯| C2
    
    style Producer fill:#e1f5ff
    style C1 fill:#e8f5e9
    style C2 fill:#fff3e0
```

#### ğŸ“‹ å…³é”®æœ¯è¯­è§£é‡Š

| æœ¯è¯­ | è§£é‡Š | ç±»æ¯” |
|------|------|------|
| **Broker** | KafkaæœåŠ¡å™¨èŠ‚ç‚¹ | é‚®å±€çš„ä¸€ä¸ªåˆ†å±€ |
| **Topic** | æ¶ˆæ¯ä¸»é¢˜/åˆ†ç±» | é‚®ä»¶çš„ç±»å‹ï¼ˆå¿«é€’ã€ä¿¡ä»¶ï¼‰ |
| **Partition** | ä¸»é¢˜çš„åˆ†åŒº | æ¯ä¸ªç±»å‹æœ‰å¤šä¸ªé‚®ç®± |
| **Producer** | æ¶ˆæ¯ç”Ÿäº§è€… | å¯„ä¿¡çš„äºº |
| **Consumer** | æ¶ˆæ¯æ¶ˆè´¹è€… | æ”¶ä¿¡çš„äºº |
| **Consumer Group** | æ¶ˆè´¹è€…ç»„ | åŒä¸€å®¶å…¬å¸çš„å¤šä¸ªæ”¶ä»¶äºº |
| **Offset** | æ¶ˆæ¯åç§»é‡ | è¯»åˆ°ç¬¬å‡ å°ä¿¡äº† |

---

### 2. **æ¶ˆæ¯ç”Ÿäº§ä¸æ¶ˆè´¹è¯¦è§£**

#### ç”Ÿäº§è€…å‘é€æ¶ˆæ¯

```java
// 1. é…ç½®Kafkaç”Ÿäº§è€…
Properties props = new Properties();
props.put("bootstrap. servers", "192.168.1.100:9092");  // Kafkaåœ°å€
props.put("key.serializer", "org.apache.kafka.common.serialization. StringSerializer");
props.put("value.serializer", "org. apache.kafka.common.serialization.StringSerializer");

KafkaProducer<String, String> producer = new KafkaProducer<>(props);

// 2. åˆ›å»ºè®¢å•åå‘é€æ¶ˆæ¯
public void createOrder(Order order) {
    // ä¿å­˜è®¢å•åˆ°MySQL
    orderDao.save(order);
    
    // å‘é€æ¶ˆæ¯åˆ°Kafka
    ProducerRecord<String, String> record = new ProducerRecord<>(
        "order-topic",              // Topicåç§°
        order.getUserId(),          // Keyï¼ˆç”¨äºåˆ†åŒºï¼‰
        JSON.toJSONString(order)    // Valueï¼ˆæ¶ˆæ¯å†…å®¹ï¼‰
    );
    
    // å¼‚æ­¥å‘é€
    producer.send(record, new Callback() {
        @Override
        public void onCompletion(RecordMetadata metadata, Exception e) {
            if (e != null) {
                log.error("å‘é€å¤±è´¥", e);
                // å¯ä»¥é‡è¯•æˆ–è®°å½•åˆ°æ•°æ®åº“
            } else {
                log.info("å‘é€æˆåŠŸï¼ŒPartition: {}, Offset: {}", 
                    metadata.partition(), metadata.offset());
            }
        }
    });
}
```

#### æ¶ˆè´¹è€…æ¶ˆè´¹æ¶ˆæ¯

```java
// 1. é…ç½®Kafkaæ¶ˆè´¹è€…
Properties props = new Properties();
props.put("bootstrap.servers", "192.168.1.100:9092");
props.put("group.id", "inventory-service");  // æ¶ˆè´¹è€…ç»„ID
props.put("key.deserializer", "org.apache. kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

// 2. è®¢é˜…Topic
consumer.subscribe(Arrays.asList("order-topic"));

// 3. æŒç»­æ‹‰å–æ¶ˆæ¯
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    
    for (ConsumerRecord<String, String> record : records) {
        // è§£ææ¶ˆæ¯
        Order order = JSON.parseObject(record.value(), Order.class);
        
        // å¤„ç†ä¸šåŠ¡é€»è¾‘
        inventoryService.reduceStock(order. getProductId(), order.getQuantity());
        
        System.out.printf("Partition: %d, Offset: %d, Key: %s, Value: %s%n",
            record.partition(), record.offset(), record.key(), record.value());
    }
    
    // æ‰‹åŠ¨æäº¤offsetï¼ˆç¡®ä¿æ¶ˆæ¯å¤„ç†æˆåŠŸåå†æäº¤ï¼‰
    consumer. commitSync();
}
```

---

### 3. **åˆ†åŒºæœºåˆ¶è¯¦è§£**

#### ä¸ºä»€ä¹ˆéœ€è¦åˆ†åŒºï¼Ÿ

```
åœºæ™¯ï¼šè®¢å•Topicæ¯ç§’10ä¸‡æ¡æ¶ˆæ¯

âŒ å•åˆ†åŒºï¼š
æ‰€æœ‰æ¶ˆæ¯åœ¨ä¸€ä¸ªé˜Ÿåˆ— â†’ åªèƒ½ä¸€ä¸ªæ¶ˆè´¹è€…è¯» â†’ æ€§èƒ½ç“¶é¢ˆ

âœ… å¤šåˆ†åŒºï¼ˆæ¯”å¦‚10ä¸ªï¼‰ï¼š
æ¶ˆæ¯åˆ†æ•£åˆ°10ä¸ªé˜Ÿåˆ— â†’ 10ä¸ªæ¶ˆè´¹è€…å¹¶è¡Œè¯» â†’ æ€§èƒ½æå‡10å€
```

#### åˆ†åŒºç­–ç•¥

```java
// ç­–ç•¥1ï¼šæ ¹æ®Keyçš„Hashåˆ†åŒºï¼ˆç›¸åŒKeyè¿›åŒä¸€åˆ†åŒºï¼Œä¿è¯é¡ºåºï¼‰
record = new ProducerRecord<>("order-topic", userId, orderData);
// userIdç›¸åŒçš„è®¢å•ä¼šè¿›å…¥åŒä¸€ä¸ªåˆ†åŒºï¼Œä¿è¯è¯¥ç”¨æˆ·çš„è®¢å•é¡ºåº

// ç­–ç•¥2ï¼šè½®è¯¢åˆ†åŒºï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
record = new ProducerRecord<>("order-topic", null, orderData);
// Keyä¸ºnullæ—¶ï¼Œè½®æµå‘é€åˆ°å„ä¸ªåˆ†åŒº

// ç­–ç•¥3ï¼šè‡ªå®šä¹‰åˆ†åŒºå™¨
public class CustomPartitioner implements Partitioner {
    @Override
    public int partition(String topic, Object key, byte[] keyBytes,
                        Object value, byte[] valueBytes, Cluster cluster) {
        // VIPç”¨æˆ·å‘åˆ°åˆ†åŒº0ï¼ˆé«˜ä¼˜å…ˆçº§å¤„ç†ï¼‰
        if (isVipUser(key)) {
            return 0;
        }
        // æ™®é€šç”¨æˆ·å‘åˆ°å…¶ä»–åˆ†åŒº
        return Utils.toPositive(Utils.murmur2(keyBytes)) % (cluster.partitionCountForTopic(topic) - 1) + 1;
    }
}
```

---

### 4. **æ¶ˆè´¹è€…ç»„æœºåˆ¶**

```mermaid
graph TB
    subgraph "Kafka Topic:  3ä¸ªåˆ†åŒº"
        P0[Partition 0]
        P1[Partition 1]
        P2[Partition 2]
    end
    
    subgraph "æ¶ˆè´¹è€…ç»„A: åº“å­˜æœåŠ¡ï¼ˆ3ä¸ªå®ä¾‹ï¼‰"
        C1A[æ¶ˆè´¹è€…1]
        C2A[æ¶ˆè´¹è€…2]
        C3A[æ¶ˆè´¹è€…3]
    end
    
    subgraph "æ¶ˆè´¹è€…ç»„B:  ç§¯åˆ†æœåŠ¡ï¼ˆ2ä¸ªå®ä¾‹ï¼‰"
        C1B[æ¶ˆè´¹è€…1]
        C2B[æ¶ˆè´¹è€…2]
    end
    
    P0 --> C1A
    P1 --> C2A
    P2 --> C3A
    
    P0 --> C1B
    P1 --> C1B
    P2 --> C2B
    
    style P0 fill:#e3f2fd
    style P1 fill:#e3f2fd
    style P2 fill:#e3f2fd
    style C1A fill:#e8f5e9
    style C2A fill:#e8f5e9
    style C3A fill:#e8f5e9
    style C1B fill:#fff3e0
    style C2B fill:#fff3e0
```

**å…³é”®è§„åˆ™**ï¼š
1. **åŒä¸€æ¶ˆè´¹è€…ç»„å†…**ï¼šä¸€ä¸ªåˆ†åŒºåªèƒ½è¢«ä¸€ä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹ï¼ˆé¿å…é‡å¤ï¼‰
2. **ä¸åŒæ¶ˆè´¹è€…ç»„**ï¼šå¯ä»¥é‡å¤æ¶ˆè´¹åŒä¸€æ¡æ¶ˆæ¯ï¼ˆå®ç°å¹¿æ’­ï¼‰
3. **æ¶ˆè´¹è€…æ•°é‡ > åˆ†åŒºæ•°**ï¼šéƒ¨åˆ†æ¶ˆè´¹è€…ä¼šç©ºé—²

---

### 5. **Offset åç§»é‡ç®¡ç†**

#### Offset çš„ä½œç”¨

```
Partition 0çš„æ¶ˆæ¯é˜Ÿåˆ—ï¼š
[æ¶ˆæ¯0] [æ¶ˆæ¯1] [æ¶ˆæ¯2] [æ¶ˆæ¯3] [æ¶ˆæ¯4] [æ¶ˆæ¯5] ... 
                  â†‘
                Offset=2ï¼ˆæ¶ˆè´¹è€…å·²è¯»åˆ°è¿™é‡Œï¼‰
```

#### ä¸‰ç§æäº¤æ–¹å¼

```java
// 1. è‡ªåŠ¨æäº¤ï¼ˆç®€å•ä½†å¯èƒ½ä¸¢æ¶ˆæ¯ï¼‰
props.put("enable.auto.commit", "true");
props.put("auto.commit.interval.ms", "1000");  // æ¯ç§’è‡ªåŠ¨æäº¤

// é£é™©ï¼šæ¶ˆæ¯å–å‡ºåè¿˜æ²¡å¤„ç†å®Œï¼Œç¨‹åºå´©æºƒï¼Œoffsetå·²æäº¤ â†’ æ¶ˆæ¯ä¸¢å¤±

// 2. æ‰‹åŠ¨åŒæ­¥æäº¤ï¼ˆå®‰å…¨ä½†æ…¢ï¼‰
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        processRecord(record);  // å¤„ç†æ¶ˆæ¯
    }
    consumer.commitSync();  // å¤„ç†å®Œæ‰æäº¤ï¼Œé˜»å¡ç­‰å¾…ç¡®è®¤
}

// 3. æ‰‹åŠ¨å¼‚æ­¥æäº¤ï¼ˆæ€§èƒ½å¥½ï¼‰
consumer.commitAsync(new OffsetCommitCallback() {
    @Override
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception e) {
        if (e != null) {
            log.error("æäº¤å¤±è´¥", e);
        }
    }
});
```

---

### 6. **é«˜å¯ç”¨æœºåˆ¶**

#### å‰¯æœ¬æœºåˆ¶ï¼ˆReplicationï¼‰

```mermaid
graph TB
    subgraph "Partition 0çš„å‰¯æœ¬åˆ†å¸ƒ"
        L[Leaderå‰¯æœ¬<br/>Broker 1<br/>è´Ÿè´£è¯»å†™]
        F1[Followerå‰¯æœ¬1<br/>Broker 2<br/>åŒæ­¥å¤‡ä»½]
        F2[Followerå‰¯æœ¬2<br/>Broker 3<br/>åŒæ­¥å¤‡ä»½]
    end
    
    Producer[ç”Ÿäº§è€…] -->|å†™å…¥| L
    Consumer[æ¶ˆè´¹è€…] -->|è¯»å–| L
    
    L -.->|åŒæ­¥æ•°æ®| F1
    L -.->|åŒæ­¥æ•°æ®| F2
    
    L -->|LeaderæŒ‚äº†| F1
    F1 -->|æå‡ä¸ºæ–°Leader| NewL[æ–°Leader<br/>Broker 2]
    
    style L fill:#4caf50
    style F1 fill:#ffeb3b
    style F2 fill:#ffeb3b
    style NewL fill:#4caf50
```

**é…ç½®ç¤ºä¾‹**ï¼š
```properties
# æ¯ä¸ªPartitionæœ‰3ä¸ªå‰¯æœ¬
replication.factor=3

# è‡³å°‘2ä¸ªå‰¯æœ¬åŒæ­¥æˆåŠŸæ‰ç®—å†™å…¥æˆåŠŸ
min.insync. replicas=2
```

---

### 7. **å®é™…åº”ç”¨åœºæ™¯**

#### åœºæ™¯1ï¼šç§’æ€ç³»ç»Ÿ

```java
// ç”¨æˆ·ç‚¹å‡»ç§’æ€æŒ‰é’®
@PostMapping("/seckill")
public Result seckill(Long productId, Long userId) {
    // 1. ç«‹å³è¿”å›"æ’é˜Ÿä¸­"
    String requestId = UUID.randomUUID().toString();
    
    // 2. å‘é€åˆ°Kafkaï¼ˆå¼‚æ­¥å¤„ç†ï¼‰
    SeckillRequest request = new SeckillRequest(requestId, productId, userId);
    kafkaTemplate.send("seckill-topic", request);
    
    // 3. ç«‹å³è¿”å›ç»™ç”¨æˆ·
    return Result.success("æ‚¨çš„è¯·æ±‚æ­£åœ¨å¤„ç†ï¼Œè¯·ç¨å€™æŸ¥è¯¢ç»“æœ", requestId);
}

// æ¶ˆè´¹è€…æ…¢æ…¢å¤„ç†
@KafkaListener(topics = "seckill-topic", concurrency = "10")  // 10ä¸ªçº¿ç¨‹å¹¶è¡Œ
public void handleSeckill(SeckillRequest request) {
    // 1. æ£€æŸ¥åº“å­˜ï¼ˆRedisï¼‰
    Long stock = redisTemplate.opsForValue().decrement("stock:" + request.getProductId());
    
    if (stock >= 0) {
        // 2. åˆ›å»ºè®¢å•ï¼ˆMySQLï¼‰
        Order order = createOrder(request);
        
        // 3. é€šçŸ¥ç”¨æˆ·æˆåŠŸ
        notifyUser(request. getUserId(), "ç§’æ€æˆåŠŸï¼");
    } else {
        // 4. æ¢å¤åº“å­˜
        redisTemplate.opsForValue().increment("stock:" + request.getProductId());
        
        // 5. é€šçŸ¥ç”¨æˆ·å¤±è´¥
        notifyUser(request.getUserId(), "å•†å“å·²å”®ç½„");
    }
}
```

#### åœºæ™¯2ï¼šæ—¥å¿—æ”¶é›†

```java
// å„ä¸ªæœåŠ¡æ‰“æ—¥å¿—
public class KafkaLogAppender extends AppenderBase<ILoggingEvent> {
    @Override
    protected void append(ILoggingEvent event) {
        String log = event.getFormattedMessage();
        kafkaProducer.send(new ProducerRecord<>("app-logs", log));
    }
}

// æ—¥å¿—æ¶ˆè´¹è€…ï¼ˆELKæ¶æ„ï¼‰
@KafkaListener(topics = "app-logs")
public void consumeLog(String log) {
    // è§£ææ—¥å¿—
    LogEntry entry = parseLog(log);
    
    // å­˜å…¥Elasticsearchï¼ˆæ–¹ä¾¿æœç´¢ï¼‰
    elasticsearchTemplate.save(entry);
    
    // å¦‚æœæ˜¯ERRORçº§åˆ«ï¼Œå‘é€å‘Šè­¦
    if (entry.getLevel().equals("ERROR")) {
        alertService.sendAlert(entry);
    }
}
```

#### åœºæ™¯3ï¼šæ•°æ®åŒæ­¥

```java
// MySQLæ•°æ®å˜åŒ– â†’ åŒæ­¥åˆ°ES
@KafkaListener(topics = "mysql-binlog")
public void syncToElasticsearch(BinlogEvent event) {
    if (event.getType() == EventType.INSERT) {
        // æ–°å¢æ•°æ®
        elasticsearchRepository.save(event.getData());
    } else if (event.getType() == EventType.UPDATE) {
        // æ›´æ–°æ•°æ®
        elasticsearchRepository.update(event.getData());
    } else if (event.getType() == EventType.DELETE) {
        // åˆ é™¤æ•°æ®
        elasticsearchRepository.delete(event.getId());
    }
}
```

---

## ä¸‰ã€Redis æ·±åº¦è§£æ

### 1. **æ•°æ®ç»“æ„è¯¦è§£**

#### äº”å¤§åŸºç¡€æ•°æ®ç»“æ„

```mermaid
graph LR
    Redis[Redisæ•°æ®ç±»å‹] --> String[String<br/>å­—ç¬¦ä¸²]
    Redis --> Hash[Hash<br/>å“ˆå¸Œè¡¨]
    Redis --> List[List<br/>åˆ—è¡¨]
    Redis --> Set[Set<br/>é›†åˆ]
    Redis --> ZSet[Sorted Set<br/>æœ‰åºé›†åˆ]
    
    String --> S1[ç¼“å­˜å¯¹è±¡<br/>è®¡æ•°å™¨<br/>åˆ†å¸ƒå¼é”]
    Hash --> H1[å­˜å‚¨å¯¹è±¡<br/>è´­ç‰©è½¦]
    List --> L1[æ¶ˆæ¯é˜Ÿåˆ—<br/>æœ€æ–°åˆ—è¡¨]
    Set --> SE1[å»é‡<br/>å…±åŒå¥½å‹]
    ZSet --> Z1[æ’è¡Œæ¦œ<br/>å»¶æ—¶é˜Ÿåˆ—]
    
    style String fill:#e3f2fd
    style Hash fill:#e8f5e9
    style List fill:#fff3e0
    style Set fill:#fce4ec
    style ZSet fill:#f3e5f5
```

---

#### Stringï¼ˆå­—ç¬¦ä¸²ï¼‰

```bash
# 1. ç®€å•ç¼“å­˜
SET user:1001 '{"name":"å¼ ä¸‰","age":25}'
GET user:1001

# 2. è®¡æ•°å™¨ï¼ˆåŸå­æ“ä½œï¼‰
INCR page:view:count       # é¡µé¢è®¿é—®é‡ +1
INCRBY score:user:1001 10  # ç”¨æˆ·ç§¯åˆ† +10
DECR stock:product:888     # åº“å­˜ -1

# 3. åˆ†å¸ƒå¼é”
SET lock: order:12345 "locked" NX EX 10
# NX = Not Existï¼ˆé”®ä¸å­˜åœ¨æ‰è®¾ç½®ï¼‰
# EX 10 = 10ç§’åè¿‡æœŸ
```

**Javaä»£ç **ï¼š
```java
// é¡µé¢è®¿é—®è®¡æ•°
public void recordPageView(String pageId) {
    redisTemplate.opsForValue().increment("page: view:" + pageId);
}

// è·å–è®¿é—®é‡
public Long getPageView(String pageId) {
    return redisTemplate.opsForValue().get("page:view:" + pageId);
}

// åˆ†å¸ƒå¼é”
public boolean tryLock(String key, int expireSeconds) {
    return redisTemplate. opsForValue()
        .setIfAbsent(key, "locked", expireSeconds, TimeUnit.SECONDS);
}
```

---

#### Hashï¼ˆå“ˆå¸Œè¡¨ï¼‰

```bash
# å­˜å‚¨ç”¨æˆ·ä¿¡æ¯
HSET user:1001 name "å¼ ä¸‰"
HSET user:1001 age 25
HSET user:1001 city "åŒ—äº¬"

# æ‰¹é‡è®¾ç½®
HMSET user:1002 name "æå››" age 30 city "ä¸Šæµ·"

# è·å–å•ä¸ªå­—æ®µ
HGET user:1001 name         # è¿”å› "å¼ ä¸‰"

# è·å–æ‰€æœ‰å­—æ®µ
HGETALL user:1001
# è¿”å›ï¼š
# 1) "name"
# 2) "å¼ ä¸‰"
# 3) "age"
# 4) "25"
# 5) "city"
# 6) "åŒ—äº¬"

# è´­ç‰©è½¦åœºæ™¯
HSET cart:user:1001 product: 888 2    # å•†å“888æ•°é‡ä¸º2
HSET cart:user:1001 product:999 1
HINCRBY cart:user:1001 product:888 1  # å•†å“888æ•°é‡ +1
```

**Javaä»£ç **ï¼š
```java
// å­˜å‚¨ç”¨æˆ·å¯¹è±¡
public void saveUser(User user) {
    Map<String, String> userMap = new HashMap<>();
    userMap.put("name", user. getName());
    userMap.put("age", String.valueOf(user.getAge()));
    userMap.put("city", user.getCity());
    
    redisTemplate.opsForHash().putAll("user:" + user.getId(), userMap);
}

// è·å–ç”¨æˆ·å¯¹è±¡
public User getUser(Long userId) {
    Map<Object, Object> entries = redisTemplate.opsForHash()
        .entries("user:" + userId);
    
    User user = new User();
    user.setName((String) entries.get("name"));
    user.setAge(Integer.parseInt((String) entries.get("age")));
    user.setCity((String) entries.get("city"));
    return user;
}

// è´­ç‰©è½¦åŠ å•†å“
public void addToCart(Long userId, Long productId, int quantity) {
    redisTemplate.opsForHash()
        .increment("cart: user:" + userId, "product:" + productId, quantity);
}
```

---

#### Listï¼ˆåˆ—è¡¨ï¼‰

```bash
# æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆå·¦è¿›å³å‡ºï¼‰
LPUSH queue:email "å‘é€é‚®ä»¶ç»™user1"
LPUSH queue:email "å‘é€é‚®ä»¶ç»™user2"
RPOP queue:email                      # å–å‡º "å‘é€é‚®ä»¶ç»™user1"

# æœ€æ–°æ–‡ç« åˆ—è¡¨
LPUSH articles:latest "æ–‡ç« ID: 999"
LPUSH articles:latest "æ–‡ç« ID:998"
LRANGE articles:latest 0 9            # è·å–æœ€æ–°10ç¯‡æ–‡ç« 

# é˜»å¡é˜Ÿåˆ—
BRPOP queue:email 10                  # é˜»å¡10ç§’ç­‰å¾…æ¶ˆæ¯
```

**Javaä»£ç **ï¼š
```java
// å‘å¸ƒæ–‡ç« ï¼ˆåŠ å…¥æœ€æ–°åˆ—è¡¨ï¼‰
public void publishArticle(Long articleId) {
    redisTemplate.opsForList().leftPush("articles: latest", articleId. toString());
    
    // ä¿æŒåˆ—è¡¨åªæœ‰100æ¡
    redisTemplate. opsForList().trim("articles:latest", 0, 99);
}

// è·å–æœ€æ–°æ–‡ç« 
public List<String> getLatestArticles(int count) {
    return redisTemplate.opsForList().range("articles:latest", 0, count - 1);
}

// ç®€å•æ¶ˆæ¯é˜Ÿåˆ—
public void sendTask(String task) {
    redisTemplate. opsForList().leftPush("task:queue", task);
}

public String getTask() {
    return redisTemplate. opsForList().rightPop("task:queue");
}
```

---

#### Setï¼ˆé›†åˆï¼‰

```bash
# ç”¨æˆ·æ ‡ç­¾
SADD user:1001:tags "Java" "Redis" "MySQL"
SADD user:1002:tags "Python" "Redis" "MongoDB"

# å…±åŒæ ‡ç­¾ï¼ˆäº¤é›†ï¼‰
SINTER user: 1001:tags user:1002:tags   # è¿”å› "Redis"

# æŠ½å¥–ï¼ˆéšæœºå–ï¼‰
SADD lottery:users "user1" "user2" "user3" "user4"
SRANDMEMBER lottery:users 1            # éšæœºæŠ½1ä¸ª
SPOP lottery:users 1                   # éšæœºæŠ½1ä¸ªå¹¶ç§»é™¤

# å»é‡ï¼ˆç‚¹èµï¼‰
SADD article:999:likes "user1"
SADD article:999:likes "user1"         # é‡å¤æ·»åŠ æ— æ•ˆ
SCARD article:999:likes                # ç»Ÿè®¡ç‚¹èµæ•°
```

**Javaä»£ç **ï¼š
```java
// ç”¨æˆ·ç‚¹èµ
public void likeArticle(Long articleId, Long userId) {
    redisTemplate.opsForSet().add("article:" + articleId + ":likes", userId. toString());
}

// å–æ¶ˆç‚¹èµ
public void unlikeArticle(Long articleId, Long userId) {
    redisTemplate.opsForSet().remove("article:" + articleId + ":likes", userId.toString());
}

// æ˜¯å¦å·²ç‚¹èµ
public boolean hasLiked(Long articleId, Long userId) {
    return redisTemplate.opsForSet()
        .isMember("article:" + articleId + ":likes", userId.toString());
}

// ç‚¹èµæ€»æ•°
public Long getLikeCount(Long articleId) {
    return redisTemplate.opsForSet().size("article:" + articleId + ": likes");
}

// å…±åŒå¥½å‹
public Set<String> getCommonFriends(Long userId1, Long userId2) {
    return redisTemplate.opsForSet()
        .intersect("user:" + userId1 + ":friends", "user:" + userId2 + ":friends");
}
```

---

#### Sorted Setï¼ˆæœ‰åºé›†åˆï¼‰

```bash
# æ’è¡Œæ¦œ
ZADD rank:score user1 100
ZADD rank:score user2 200
ZADD rank:score user3 150

# è·å–å‰3å
ZREVRANGE rank:score 0 2 WITHSCORES
# è¿”å›ï¼š
# 1) "user2"
# 2) "200"
# 3) "user3"
# 4) "150"
# 5) "user1"
# 6) "100"

# è·å–æŸä¸ªç”¨æˆ·çš„æ’å
ZREVRANK rank:score user3              # è¿”å› 1ï¼ˆç¬¬2åï¼Œä»0å¼€å§‹ï¼‰

# å¢åŠ åˆ†æ•°
ZINCRBY rank: score 50 user1            # user1åˆ†æ•° +50

# å»¶æ—¶é˜Ÿåˆ—ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
ZADD delay:queue task1 1640000000      # Unixæ—¶é—´æˆ³
ZADD delay:queue task2 1640000100
ZRANGEBYSCORE delay:queue 0 å½“å‰æ—¶é—´æˆ³  # å–å‡ºåˆ°æœŸçš„ä»»åŠ¡
```

**Javaä»£ç **ï¼š
```java
// æ·»åŠ ç”¨æˆ·åˆ†æ•°
public void addScore(Long userId, double score) {
    redisTemplate.opsForZSet().add("rank:score", userId.toString(), score);
}

// å¢åŠ åˆ†æ•°
public void incrementScore(Long userId, double delta) {
    redisTemplate. opsForZSet().incrementScore("rank:score", userId. toString(), delta);
}

// è·å–æ’è¡Œæ¦œï¼ˆå‰Nåï¼‰
public Set<ZSetOperations.TypedTuple<String>> getTopN(int n) {
    return redisTemplate.opsForZSet()
        .reverseRangeWithScores("rank:score", 0, n - 1);
}

// è·å–ç”¨æˆ·æ’å
public Long getUserRank(Long userId) {
    return redisTemplate.opsForZSet()
        .reverseRank("rank:score", userId.toString());
}

// å»¶æ—¶ä»»åŠ¡é˜Ÿåˆ—
public void addDelayTask(String taskId, long executeTime) {
    redisTemplate.opsForZSet().add("delay:queue", taskId, executeTime);
}

// è·å–åˆ°æœŸä»»åŠ¡
public Set<String> getExpiredTasks() {
    long now = System.currentTimeMillis();
    return redisTemplate. opsForZSet()
        .rangeByScore("delay:queue", 0, now);
}
```

---

### 2. **ç¼“å­˜ç­–ç•¥è¯¦è§£**

#### ç¼“å­˜æ›´æ–°ç­–ç•¥

```mermaid
graph TD
    A[æ•°æ®æ›´æ–°è¯·æ±‚] --> B{é€‰æ‹©ç­–ç•¥}
    
    B -->|ç­–ç•¥1| C[Cache Aside<br/>æ—è·¯ç¼“å­˜]
    B -->|ç­–ç•¥2| D[Read/Write Through<br/>è¯»å†™ç©¿é€]
    B -->|ç­–ç•¥3| E[Write Behind<br/>å¼‚æ­¥å†™å…¥]
    
    C --> C1[æ›´æ–°æ•°æ®åº“]
    C1 --> C2[åˆ é™¤ç¼“å­˜]
    C2 --> C3[ä¸‹æ¬¡è¯»å–æ—¶<br/>é‡æ–°åŠ è½½]
    
    D --> D1[åº”ç”¨åªæ“ä½œç¼“å­˜]
    D1 --> D2[ç¼“å­˜å±‚è´Ÿè´£<br/>åŒæ­¥æ•°æ®åº“]
    
    E --> E1[å…ˆå†™ç¼“å­˜]
    E1 --> E2[å¼‚æ­¥æ‰¹é‡<br/>å†™å…¥æ•°æ®åº“]
    
    style C fill:#e3f2fd
    style D fill:#e8f5e9
    style E fill:#fff3e0
```

#### ç­–ç•¥1ï¼šCache Asideï¼ˆæœ€å¸¸ç”¨ï¼‰

```java
// è¯»æ•°æ®
public Product getProduct(Long id) {
    // 1. å…ˆæŸ¥ç¼“å­˜
    String cacheKey = "product:" + id;
    Product product = redisTemplate.opsForValue().get(cacheKey);
    
    if (product != null) {
        return product;  // ç¼“å­˜å‘½ä¸­
    }
    
    // 2. ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥æ•°æ®åº“
    product = productDao.selectById(id);
    
    if (product != null) {
        // 3. å†™å…¥ç¼“å­˜
        redisTemplate.opsForValue().set(cacheKey, product, 1, TimeUnit.HOURS);
    }
    
    return product;
}

// å†™æ•°æ®
public void updateProduct(Product product) {
    // 1. å…ˆæ›´æ–°æ•°æ®åº“
    productDao.updateById(product);
    
    // 2. åˆ é™¤ç¼“å­˜ï¼ˆè€Œä¸æ˜¯æ›´æ–°ç¼“å­˜ï¼‰
    redisTemplate.delete("product:" + product. getId());
    
    // ä¸ºä»€ä¹ˆåˆ é™¤è€Œä¸æ˜¯æ›´æ–°ï¼Ÿ
    // å› ä¸ºå¯èƒ½æœ‰å¤šä¸ªè¯·æ±‚åŒæ—¶æ›´æ–°ï¼Œåˆ é™¤ç¼“å­˜æ›´å®‰å…¨
}
```

#### ç­–ç•¥2ï¼šRead/Write Through

```java
// ä½¿ç”¨Spring Cacheè‡ªåŠ¨ç®¡ç†
@Cacheable(value = "products", key = "#id")
public Product getProduct(Long id) {
    // Springè‡ªåŠ¨å¤„ç†ï¼šå…ˆæŸ¥ç¼“å­˜ï¼Œæœªå‘½ä¸­åˆ™æ‰§è¡Œæ–¹æ³•å¹¶ç¼“å­˜ç»“æœ
    return productDao.selectById(id);
}

@CachePut(value = "products", key = "#product.id")
public Product updateProduct(Product product) {
    // Springè‡ªåŠ¨å¤„ç†ï¼šæ›´æ–°æ•°æ®åº“åæ›´æ–°ç¼“å­˜
    productDao.updateById(product);
    return product;
}

@CacheEvict(value = "products", key = "#id")
public void deleteProduct(Long id) {
    // Springè‡ªåŠ¨å¤„ç†ï¼šåˆ é™¤æ•°æ®åº“ååˆ é™¤ç¼“å­˜
    productDao.deleteById(id);
}
```

---

### 3. **ç¼“å­˜é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ**

#### é—®é¢˜1ï¼šç¼“å­˜ç©¿é€ï¼ˆæŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®ï¼‰

```
åœºæ™¯ï¼šæ¶æ„æ”»å‡»æŸ¥è¯¢ID=-1çš„å•†å“
è¯·æ±‚ â†’ ç¼“å­˜æ²¡æœ‰ â†’ æ•°æ®åº“ä¹Ÿæ²¡æœ‰ â†’ æ¯æ¬¡éƒ½æ‰“åˆ°æ•°æ®åº“
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```java
// æ–¹æ¡ˆ1ï¼šç¼“å­˜ç©ºå€¼
public Product getProduct(Long id) {
    String cacheKey = "product:" + id;
    Product product = redisTemplate.opsForValue().get(cacheKey);
    
    if (product != null) {
        if (product.getId() == null) {
            return null;  // ä¹‹å‰æŸ¥è¿‡ï¼Œæ•°æ®åº“æ²¡æœ‰
        }
        return product;
    }
    
    product = productDao.selectById(id);
    
    if (product == null) {
        // ç¼“å­˜ä¸€ä¸ªç©ºå¯¹è±¡ï¼Œè¿‡æœŸæ—¶é—´çŸ­ä¸€ç‚¹
        redisTemplate. opsForValue().set(cacheKey, new Product(), 5, TimeUnit.MINUTES);
    } else {
        redisTemplate. opsForValue().set(cacheKey, product, 1, TimeUnit.HOURS);
    }
    
    return product;
}

// æ–¹æ¡ˆ2ï¼šå¸ƒéš†è¿‡æ»¤å™¨ï¼ˆBloom Filterï¼‰
@Autowired
private RedissonClient redissonClient;

public Product getProduct(Long id) {
    // 1. å¸ƒéš†è¿‡æ»¤å™¨åˆ¤æ–­æ˜¯å¦å­˜åœ¨
    RBloomFilter<Long> bloomFilter = redissonClient.getBloomFilter("product:bloom");
    if (! bloomFilter.contains(id)) {
        return null;  // ä¸€å®šä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›
    }
    
    // 2. å¯èƒ½å­˜åœ¨ï¼ŒæŸ¥ç¼“å­˜å’Œæ•°æ®åº“
    // ... æ­£å¸¸é€»è¾‘
}

// åˆå§‹åŒ–å¸ƒéš†è¿‡æ»¤å™¨
public void initBloomFilter() {
    RBloomFilter<Long> bloomFilter = redissonClient.getBloomFilter("product:bloom");
    bloomFilter.tryInit(100000, 0.01);  // é¢„è®¡10ä¸‡æ¡æ•°æ®ï¼Œ1%è¯¯åˆ¤ç‡
    
    // åŠ è½½æ‰€æœ‰å•†å“ID
    List<Long> productIds = productDao.selectAllIds();
    productIds.forEach(bloomFilter::add);
}
```

---

#### é—®é¢˜2ï¼šç¼“å­˜å‡»ç©¿ï¼ˆçƒ­ç‚¹æ•°æ®è¿‡æœŸï¼‰

```
åœºæ™¯ï¼šçˆ†æ¬¾å•†å“ç¼“å­˜è¿‡æœŸç¬é—´
1000ä¸ªè¯·æ±‚åŒæ—¶åˆ°è¾¾ â†’ ç¼“å­˜éƒ½æ²¡æœ‰ â†’ 1000ä¸ªè¯·æ±‚éƒ½æ‰“åˆ°æ•°æ®åº“
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```java
// æ–¹æ¡ˆ1ï¼šäº’æ–¥é”ï¼ˆåªè®©ä¸€ä¸ªè¯·æ±‚æŸ¥æ•°æ®åº“ï¼‰
public Product getProduct(Long id) {
    String cacheKey = "product:" + id;
    Product product = redisTemplate.opsForValue().get(cacheKey);
    
    if (product != null) {
        return product;
    }
    
    // å°è¯•è·å–é”
    String lockKey = "lock:product:" + id;
    boolean locked = redisTemplate.opsForValue()
        .setIfAbsent(lockKey, "1", 10, TimeUnit. SECONDS);
    
    if (locked) {
        try {
            // æ‹¿åˆ°é”ï¼ŒæŸ¥æ•°æ®åº“
            product = productDao.selectById(id);
            redisTemplate. opsForValue().set(cacheKey, product, 1, TimeUnit.HOURS);
            return product;
        } finally {
            redisTemplate. delete(lockKey);  // é‡Šæ”¾é”
        }
    } else {
        // æ²¡æ‹¿åˆ°é”ï¼Œç­‰å¾…ä¸€ä¸‹å†æŸ¥ç¼“å­˜
        Thread.sleep(50);
        return getProduct(id);  // é€’å½’è°ƒç”¨
    }
}

// æ–¹æ¡ˆ2ï¼šæ°¸ä¸è¿‡æœŸï¼ˆé€»è¾‘è¿‡æœŸï¼‰
public Product getProduct(Long id) {
    String cacheKey = "product:" + id;
    CacheData cacheData = redisTemplate. opsForValue().get(cacheKey);
    
    if (cacheData == null) {
        // ç¼“å­˜é‡å»º
        return rebuildCache(id);
    }
    
    // æ£€æŸ¥é€»è¾‘è¿‡æœŸæ—¶é—´
    if (cacheData.getExpireTime().isBefore(LocalDateTime.now())) {
        // å·²è¿‡æœŸï¼Œå¼‚æ­¥é‡å»ºç¼“å­˜
        executorService.submit(() -> rebuildCache(id));
        
        // è¿”å›æ—§æ•°æ®ï¼ˆè™½ç„¶è¿‡æœŸä½†å¯ç”¨ï¼‰
        return cacheData. getProduct();
    }
    
    return cacheData.getProduct();
}

private Product rebuildCache(Long id) {
    // è·å–äº’æ–¥é”
    String lockKey = "lock:product:" + id;
    if (! tryLock(lockKey)) {
        return null;  // æœ‰å…¶ä»–çº¿ç¨‹åœ¨é‡å»º
    }
    
    try {
        Product product = productDao.selectById(id);
        CacheData cacheData = new CacheData();
        cacheData.setProduct(product);
        cacheData.setExpireTime(LocalDateTime.now().plusHours(1));  // é€»è¾‘è¿‡æœŸæ—¶é—´
        
        redisTemplate.opsForValue().set("product:" + id, cacheData);  // ä¸è®¾ç½®Redisè¿‡æœŸæ—¶é—´
        return product;
    } finally {
        unlock(lockKey);
    }
}
```

---

#### é—®é¢˜3ï¼šç¼“å­˜é›ªå´©ï¼ˆå¤§é‡ç¼“å­˜åŒæ—¶è¿‡æœŸï¼‰

```
åœºæ™¯ï¼šå‡Œæ™¨2ç‚¹æ‰¹é‡å¯¼å…¥å•†å“ï¼Œè®¾ç½®1å°æ—¶è¿‡æœŸ
å‡Œæ™¨3ç‚¹ï¼Œæ‰€æœ‰ç¼“å­˜åŒæ—¶å¤±æ•ˆ â†’ æ•°æ®åº“å‹åŠ›æš´å¢
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```java
// æ–¹æ¡ˆ1ï¼šè¿‡æœŸæ—¶é—´åŠ éšæœºå€¼
public void cacheProduct(Product product) {
    int baseExpire = 3600;  // 1å°æ—¶
    int randomExpire = new Random().nextInt(300);  // 0-5åˆ†é’Ÿéšæœº
    int expire = baseExpire + randomExpire;
    
    redisTemplate.opsForValue().set(
        "product:" + product. getId(), 
        product, 
        expire, 
        TimeUnit.SECONDS
    );
}

// æ–¹æ¡ˆ2ï¼šçƒ­ç‚¹æ•°æ®æ°¸ä¸è¿‡æœŸ
public void cacheHotProduct(Product product) {
    // çƒ­é—¨å•†å“ä¸è®¾ç½®è¿‡æœŸæ—¶é—´
    redisTemplate.opsForValue().set("hot: product:" + product.getId(), product);
    
    // å®šæ—¶ä»»åŠ¡å®šæœŸæ›´æ–°
}

// æ–¹æ¡ˆ3ï¼šä½¿ç”¨Redisé›†ç¾¤ + å¤šçº§ç¼“å­˜
public Product getProduct(Long id) {
    // L1: æœ¬åœ°ç¼“å­˜ï¼ˆCaffeineï¼‰
    Product product = localCache.get(id);
    if (product != null) return product;
    
    // L2: Redisç¼“å­˜
    product = redisTemplate. opsForValue().get("product:" + id);
    if (product != null) {
        localCache.put(id, product);
        return product;
    }
    
    // L3: æ•°æ®åº“
    product = productDao.selectById(id);
    if (product != null) {
        redisTemplate.opsForValue().set("product:" + id, product, 1, TimeUnit. HOURS);
        localCache.put(id, product);
    }
    
    return product;
}
```

---

### 4. **åˆ†å¸ƒå¼é”æ·±å…¥**

#### Redisson å®ç°åˆ†å¸ƒå¼é”

```java
@Autowired
private RedissonClient redissonClient;

// ç®€å•ä½¿ç”¨
public void secKill(Long productId) {
    RLock lock = redissonClient.getLock("seckill:" + productId);
    
    try {
        // å°è¯•åŠ é”ï¼Œæœ€å¤šç­‰å¾…10ç§’ï¼Œé”30ç§’åè‡ªåŠ¨é‡Šæ”¾
        boolean locked = lock. tryLock(10, 30, TimeUnit.SECONDS);
        
        if (! locked) {
            throw new BusinessException("ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åé‡è¯•");
        }
        
        // æ‰§è¡Œä¸šåŠ¡é€»è¾‘
        int stock = getStock(productId);
        if (stock > 0) {
            reduceStock(productId);
            createOrder();
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    } finally {
        lock.unlock();  // é‡Šæ”¾é”
    }
}

// å¯é‡å…¥é”æ¼”ç¤º
public void demo() {
    RLock lock = redissonClient.getLock("mylock");
    lock.lock();
    
    try {
        method1();  // method1å†…éƒ¨ä¹Ÿå°è¯•è·å–åŒä¸€æŠŠé”
    } finally {
        lock.unlock();
    }
}

public void method1() {
    RLock lock = redissonClient.getLock("mylock");
    lock.lock();  // å¯é‡å…¥ï¼Œä¸ä¼šæ­»é”
    try {
        // ä¸šåŠ¡é€»è¾‘
    } finally {
        lock.unlock();
    }
}

// è”é”ï¼ˆMultiLockï¼‰
public void multiLock() {
    RLock lock1 = redissonClient.getLock("lock1");
    RLock lock2 = redissonClient.getLock("lock2");
    RLock lock3 = redissonClient.getLock("lock3");
    
    RedissonMultiLock multiLock = new RedissonMultiLock(lock1, lock2, lock3);
    
    try {
        multiLock. lock();
        // åŒæ—¶æŒæœ‰3æŠŠé”
    } finally {
        multiLock.unlock();
    }
}

// çº¢é”ï¼ˆRedLockï¼‰- å¤šä¸ªç‹¬ç«‹Rediså®ä¾‹
public void redLock() {
    RLock lock1 = redissonClient1.getLock("lock");
    RLock lock2 = redissonClient2.getLock("lock");
    RLock lock3 = redissonClient3.getLock("lock");
    
    RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3);
    
    try {
        // è‡³å°‘åœ¨N/2+1ä¸ªå®ä¾‹ä¸ŠåŠ é”æˆåŠŸæ‰ç®—æˆåŠŸ
        redLock.lock();
    } finally {
        redLock.unlock();
    }
}
```

---

### 5. **æŒä¹…åŒ–æœºåˆ¶**

```mermaid
graph LR
    Redis[RedisæŒä¹…åŒ–] --> RDB[RDBå¿«ç…§]
    Redis --> AOF[AOFæ—¥å¿—]
    Redis --> Mix[æ··åˆæŒä¹…åŒ–]
    
    RDB --> R1[å®šæœŸå…¨é‡å¤‡ä»½<br/>æ¢å¤å¿«<br/>æ•°æ®å¯èƒ½ä¸¢å¤±]
    AOF --> A1[è®°å½•æ¯ä¸ªå†™å‘½ä»¤<br/>æ•°æ®å®Œæ•´<br/>æ–‡ä»¶å¤§]
    Mix --> M1[RDB + AOF<br/>å…¼é¡¾æ€§èƒ½å’Œå®‰å…¨]
    
    style RDB fill:#e3f2fd
    style AOF fill:#e8f5e9
    style Mix fill:#fff3e0
```

**é…ç½®ç¤ºä¾‹**ï¼š

```conf
# RDBé…ç½®
save 900 1      # 900ç§’å†…è‡³å°‘1ä¸ªkeyå˜åŒ–ï¼Œè§¦å‘å¿«ç…§
save 300 10     # 300ç§’å†…è‡³å°‘10ä¸ªkeyå˜åŒ–
save 60 10000   # 60ç§’å†…è‡³å°‘10000ä¸ªkeyå˜åŒ–

# AOFé…ç½®
appendonly yes
appendfsync everysec  # æ¯ç§’åŒæ­¥ä¸€æ¬¡ï¼ˆæ¨èï¼‰
# appendfsync always  # æ¯ä¸ªå‘½ä»¤éƒ½åŒæ­¥ï¼ˆæœ€å®‰å…¨ä½†æ…¢ï¼‰
# appendfsync no      # ç”±æ“ä½œç³»ç»Ÿå†³å®šï¼ˆæœ€å¿«ä½†ä¸å®‰å…¨ï¼‰

# æ··åˆæŒä¹…åŒ–ï¼ˆRedis 4.0+ï¼‰
aof-use-rdb-preamble yes
```

---

## å››ã€MySQL æ·±åº¦è§£æ

### 1. **äº‹åŠ¡ACIDè¯¦è§£**

```java
// è½¬è´¦ç¤ºä¾‹
@Transactional(rollbackFor = Exception.class)
public void transfer(Long fromUserId, Long toUserId, BigDecimal amount) {
    // 1. æ‰£å‡è½¬å‡ºè´¦æˆ·
    accountDao.deductBalance(fromUserId, amount);
    
    // 2. æ¨¡æ‹Ÿå¼‚å¸¸
    if (amount.compareTo(new BigDecimal("1000")) > 0) {
        throw new RuntimeException("å•ç¬”è½¬è´¦ä¸èƒ½è¶…è¿‡1000å…ƒ");
    }
    
    // 3. å¢åŠ è½¬å…¥è´¦æˆ·
    accountDao.addBalance(toUserId, amount);
    
    // 4. è®°å½•æµæ°´
    transactionLogDao.insert(new TransactionLog(fromUserId, toUserId, amount));
}
// å¦‚æœæŠ›å‡ºå¼‚å¸¸ï¼Œ1ã€3ã€4æ­¥éª¤éƒ½ä¼šå›æ»š
```

#### ACIDç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ | å®ç°æœºåˆ¶ |
|------|------|----------|
| **åŸå­æ€§ (Atomicity)** | å…¨éƒ¨æˆåŠŸæˆ–å…¨éƒ¨å¤±è´¥ | Undo Logï¼ˆå›æ»šæ—¥å¿—ï¼‰ |
| **ä¸€è‡´æ€§ (Consistency)** | æ•°æ®å®Œæ•´æ€§çº¦æŸ | äº‹åŠ¡ + çº¦æŸ |
| **éš”ç¦»æ€§ (Isolation)** | å¹¶å‘äº‹åŠ¡äº’ä¸å¹²æ‰° | é” + MVCC |
| **æŒä¹…æ€§ (Durability)** | æäº¤åæ°¸ä¹…ä¿å­˜ | Redo Logï¼ˆé‡åšæ—¥å¿—ï¼‰ |

---

### 2. **äº‹åŠ¡éš”ç¦»çº§åˆ«**

```mermaid
graph TB
    A[äº‹åŠ¡éš”ç¦»çº§åˆ«] --> B[Read Uncommitted<br/>è¯»æœªæäº¤]
    A --> C[Read Committed<br/>è¯»å·²æäº¤]
    A --> D[Repeatable Read<br/>å¯é‡å¤è¯»é»˜è®¤]
    A --> E[Serializable<br/>ä¸²è¡ŒåŒ–]
    
    B --> B1[è„è¯»âŒ<br/>ä¸å¯é‡å¤è¯»âŒ<br/>å¹»è¯»âŒ]
    C --> C1[è„è¯»âœ…<br/>ä¸å¯é‡å¤è¯»âŒ<br/>å¹»è¯»âŒ]
    D --> D1[è„è¯»âœ…<br/>ä¸å¯é‡å¤è¯»âœ…<br/>å¹»è¯»âœ…Next-Key Lock]
    E --> E1[è„è¯»âœ…<br/>ä¸å¯é‡å¤è¯»âœ…<br/>å¹»è¯»âœ…<br/>æ€§èƒ½æœ€å·®]
    
    style D fill:#4caf50
```

#### å¹¶å‘é—®é¢˜æ¼”ç¤º

```sql
-- è„è¯»ï¼ˆRead Uncommittedä¼šå‡ºç°ï¼‰
-- äº‹åŠ¡A
BEGIN;
UPDATE account SET balance = 1000 WHERE id = 1;
-- æœªæäº¤

-- äº‹åŠ¡B
BEGIN;
SELECT balance FROM account WHERE id = 1;  -- è¯»åˆ°1000ï¼ˆäº‹åŠ¡Aæœªæäº¤çš„æ•°æ®ï¼‰
-- å¦‚æœäº‹åŠ¡Aå›æ»šï¼Œäº‹åŠ¡Bè¯»åˆ°çš„æ˜¯è„æ•°æ®


-- ä¸å¯é‡å¤è¯»ï¼ˆRead Committedä¼šå‡ºç°ï¼‰
-- äº‹åŠ¡A
BEGIN;
SELECT balance FROM account WHERE id = 1;  -- è¯»åˆ°500

-- äº‹åŠ¡B
BEGIN;
UPDATE account SET balance = 1000 WHERE id = 1;
COMMIT;

-- äº‹åŠ¡A
SELECT balance FROM account WHERE id = 1;  -- è¯»åˆ°1000ï¼ˆåŒä¸€äº‹åŠ¡å†…ä¸¤æ¬¡è¯»ç»“æœä¸åŒï¼‰


-- å¹»è¯»ï¼ˆRepeatable Readåœ¨æŸäº›æƒ…å†µä¼šå‡ºç°ï¼‰
-- äº‹åŠ¡A
BEGIN;
SELECT * FROM account WHERE balance > 500;  -- è¿”å›3æ¡

-- äº‹åŠ¡B
BEGIN;
INSERT INTO account (id, balance) VALUES (4, 600);
COMMIT;

-- äº‹åŠ¡A
SELECT * FROM account WHERE balance > 500;  -- è¿”å›4æ¡ï¼ˆå¤šäº†ä¸€æ¡å¹»å½±è®°å½•ï¼‰
```

**è®¾ç½®éš”ç¦»çº§åˆ«**ï¼š
```sql
-- å…¨å±€è®¾ç½®
SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;

-- ä¼šè¯çº§åˆ«
SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;

-- å•ä¸ªäº‹åŠ¡
SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
START TRANSACTION;
-- ... 
COMMIT;
```

---

### 3. **é”æœºåˆ¶è¯¦è§£**

#### é”çš„åˆ†ç±»

```mermaid
graph TB
    Lock[MySQLé”] --> L1[æŒ‰ç²’åº¦åˆ†ç±»]
    Lock --> L2[æŒ‰ç±»å‹åˆ†ç±»]
    
    L1 --> T1[è¡¨é”<br/>é”æ•´å¼ è¡¨]
    L1 --> R1[è¡Œé”<br/>é”å•è¡Œè®°å½•InnoDB]
    L1 --> G1[é—´éš™é”<br/>é”ç´¢å¼•é—´éš™]
    
    L2 --> S1[å…±äº«é”S<br/>è¯»é”]
    L2 --> X1[æ’ä»–é”X<br/>å†™é”]
    L2 --> I1[æ„å‘é”<br/>è¡¨çº§é”]
    
    style R1 fill:#4caf50
    style X1 fill:#ff9800
```

#### è¡Œé”ç¤ºä¾‹

```sql
-- å…±äº«é”ï¼ˆSé”ï¼‰ï¼šå…¶ä»–äº‹åŠ¡å¯ä»¥è¯»ï¼Œä¸èƒ½å†™
SELECT * FROM account WHERE id = 1 LOCK IN SHARE MODE;

-- æ’ä»–é”ï¼ˆXé”ï¼‰ï¼šå…¶ä»–äº‹åŠ¡ä¸èƒ½è¯»ä¹Ÿä¸èƒ½å†™
SELECT * FROM account WHERE id = 1 FOR UPDATE;

-- å®é™…åœºæ™¯ï¼šç§’æ€æ‰£åº“å­˜
BEGIN;

-- é”å®šå•†å“åº“å­˜è¡Œ
SELECT stock FROM product WHERE id = 888 FOR UPDATE;

-- æ£€æŸ¥åº“å­˜
IF stock > 0 THEN
    UPDATE product SET stock = stock - 1 WHERE id = 888;
    INSERT INTO orders (...) VALUES (...);
END IF;

COMMIT;
```

#### Next-Key Lockï¼ˆè§£å†³å¹»è¯»ï¼‰

```sql
-- å‡è®¾æœ‰ç´¢å¼•å€¼ï¼š10, 20, 30
-- é—´éš™ï¼š(-âˆ, 10), (10, 20), (20, 30), (30, +âˆ)

-- äº‹åŠ¡Aï¼šèŒƒå›´æŸ¥è¯¢
BEGIN;
SELECT * FROM account WHERE id BETWEEN 10 AND 30 FOR UPDATE;
-- é”ä½ï¼š(10, 20, 30]è¿™äº›è¡Œ + (10, 30)è¿™ä¸ªé—´éš™

-- äº‹åŠ¡Bï¼šå°è¯•æ’å…¥
BEGIN;
INSERT INTO account (id, balance) VALUES (15, 100);  -- è¢«é˜»å¡ï¼ˆ15åœ¨é—´éš™å†…ï¼‰
INSERT INTO account (id, balance) VALUES (5, 100);   -- å¯ä»¥æ‰§è¡Œï¼ˆ5ä¸åœ¨é—´éš™å†…ï¼‰
```

---

### 4. **ç´¢å¼•ä¼˜åŒ–**

#### ç´¢å¼•ç±»å‹

```sql
-- 1. ä¸»é”®ç´¢å¼•
CREATE TABLE users (
    id BIGINT PRIMARY KEY,
    name VARCHAR(50)
);

-- 2. å”¯ä¸€ç´¢å¼•
CREATE UNIQUE INDEX idx_email ON users(email);

-- 3. æ™®é€šç´¢å¼•
CREATE INDEX idx_name ON users(name);

-- 4. ç»„åˆç´¢å¼•ï¼ˆæœ€å·¦å‰ç¼€åŸåˆ™ï¼‰
CREATE INDEX idx_name_age_city ON users(name, age, city);

-- å¯ä»¥ä½¿ç”¨ç´¢å¼•çš„æŸ¥è¯¢ï¼š
SELECT * FROM users WHERE name = 'å¼ ä¸‰';  -- âœ…
SELECT * FROM users WHERE name = 'å¼ ä¸‰' AND age = 25;  -- âœ…
SELECT * FROM users WHERE name = 'å¼ ä¸‰' AND age = 25 AND city = 'åŒ—äº¬';  -- âœ…
SELECT * FROM users WHERE name = 'å¼ ä¸‰' AND city = 'åŒ—äº¬';  -- âœ…ï¼ˆageå¯ä»¥è·³è¿‡ï¼‰

-- ä¸èƒ½ä½¿ç”¨ç´¢å¼•çš„æŸ¥è¯¢ï¼š
SELECT * FROM users WHERE age = 25;  -- âŒï¼ˆè·³è¿‡äº†nameï¼‰
SELECT * FROM users WHERE city = 'åŒ—äº¬';  -- âŒï¼ˆè·³è¿‡äº†nameå’Œageï¼‰

-- 5. å…¨æ–‡ç´¢å¼•
CREATE FULLTEXT INDEX idx_content ON articles(content);
SELECT * FROM articles WHERE MATCH(content) AGAINST('Java Redis');

-- 6. è¦†ç›–ç´¢å¼•ï¼ˆç´¢å¼•åŒ…å«æ‰€æœ‰æŸ¥è¯¢å­—æ®µï¼‰
CREATE INDEX idx_name_age ON users(name, age);
SELECT name, age FROM users WHERE name = 'å¼ ä¸‰';  -- ä¸éœ€è¦å›è¡¨æŸ¥è¯¢
```

#### ç´¢å¼•å¤±æ•ˆåœºæ™¯

```sql
-- 1. ä½¿ç”¨å‡½æ•°
SELECT * FROM users WHERE YEAR(create_time) = 2023;  -- âŒç´¢å¼•å¤±æ•ˆ
SELECT * FROM users WHERE create_time BETWEEN '2023-01-01' AND '2023-12-31';  -- âœ…ä½¿ç”¨ç´¢å¼•

-- 2. ç±»å‹è½¬æ¢
SELECT * FROM users WHERE phone = 13800138000;  -- âŒï¼ˆphoneæ˜¯VARCHARï¼Œå‘ç”Ÿéšå¼è½¬æ¢ï¼‰
SELECT * FROM users WHERE phone = '13800138000';  -- âœ…

-- 3. æ¨¡ç³ŠæŸ¥è¯¢ï¼ˆå‰ç¼€åŒ¹é…ï¼‰
SELECT * FROM users WHERE name LIKE '%å¼ %';  -- âŒ
SELECT * FROM users WHERE name LIKE 'å¼ %';   -- âœ…

-- 4. ORæ¡ä»¶ï¼ˆéƒ¨åˆ†å­—æ®µæ— ç´¢å¼•ï¼‰
SELECT * FROM users WHERE name = 'å¼ ä¸‰' OR address = 'åŒ—äº¬';  -- âŒï¼ˆaddressæ— ç´¢å¼•ï¼‰
SELECT * FROM users WHERE name = 'å¼ ä¸‰' OR email = 'test@qq.com';  -- âœ…ï¼ˆéƒ½æœ‰ç´¢å¼•ï¼‰

-- 5. ä¸ç­‰äº
SELECT * FROM users WHERE age != 25;  -- âŒ
SELECT * FROM users WHERE age > 25 OR age < 25;  -- å¯èƒ½ä½¿ç”¨ç´¢å¼•

-- 6. IS NULL / IS NOT NULL
SELECT * FROM users WHERE email IS NULL;  -- å¯èƒ½å¤±æ•ˆï¼ˆå–å†³äºNULLå€¼æ¯”ä¾‹ï¼‰
```

---

### 5. **EXPLAINæ‰§è¡Œè®¡åˆ’**

```sql
EXPLAIN SELECT * FROM orders WHERE user_id = 1001;
```

**å…³é”®å­—æ®µ**ï¼š

| å­—æ®µ | è¯´æ˜ | é‡ç‚¹å…³æ³¨ |
|------|------|----------|
| **type** | è®¿é—®ç±»å‹ | system > const > eq_ref > ref > range > index > ALL |
| **possible_keys** | å¯èƒ½ä½¿ç”¨çš„ç´¢å¼• | - |
| **key** | å®é™…ä½¿ç”¨çš„ç´¢å¼• | NULLè¡¨ç¤ºæœªä½¿ç”¨ç´¢å¼• |
| **rows** | æ‰«æè¡Œæ•° | è¶Šå°è¶Šå¥½ |
| **Extra** | é¢å¤–ä¿¡æ¯ | Using filesortï¼ˆéœ€è¦æ’åºï¼‰<br/>Using temporaryï¼ˆéœ€è¦ä¸´æ—¶è¡¨ï¼‰<br/>Using indexï¼ˆè¦†ç›–ç´¢å¼•ï¼‰ |

**ç¤ºä¾‹åˆ†æ**ï¼š
```sql
-- å…¨è¡¨æ‰«æï¼ˆæœ€å·®ï¼‰
EXPLAIN SELECT * FROM orders WHERE amount > 100;
-- type: ALL, rows: 100000 âŒ

-- ä½¿ç”¨ç´¢å¼•ï¼ˆä¼˜åŒ–åï¼‰
CREATE INDEX idx_amount ON orders(amount);
EXPLAIN SELECT * FROM orders WHERE amount > 100;
-- type: range, rows: 5000 âœ…
```

ä½ è¯´å¾—å¯¹ï¼æˆ‘åˆšæ‰è®²è§£æ—¶ç¡®å®é—æ¼äº†å¾ˆå¤šé‡è¦å†…å®¹ã€‚è®©æˆ‘ç»§ç»­å®Œæˆå‰©ä½™çš„æ·±åº¦è§£æã€‚

---

## äº”ã€MongoDB æ·±åº¦è§£æ

### 1. **æ–‡æ¡£æ¨¡å‹ vs å…³ç³»æ¨¡å‹**

#### æ•°æ®å»ºæ¨¡å¯¹æ¯”

```javascript
// MySQLå…³ç³»æ¨¡å‹ï¼ˆéœ€è¦3å¼ è¡¨ï¼‰
-- usersè¡¨
CREATE TABLE users (
    id BIGINT PRIMARY KEY,
    name VARCHAR(50),
    email VARCHAR(100)
);

-- ordersè¡¨
CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    user_id BIGINT,
    total DECIMAL(10,2),
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- order_itemsè¡¨
CREATE TABLE order_items (
    id BIGINT PRIMARY KEY,
    order_id BIGINT,
    product_name VARCHAR(100),
    quantity INT,
    price DECIMAL(10,2),
    FOREIGN KEY (order_id) REFERENCES orders(id)
);

-- æŸ¥è¯¢éœ€è¦JOIN
SELECT u.name, o.total, oi.product_name
FROM users u
JOIN orders o ON u.id = o.user_id
JOIN order_items oi ON o.id = oi.order_id;
```

```javascript
// MongoDBæ–‡æ¡£æ¨¡å‹ï¼ˆä¸€ä¸ªé›†åˆæå®šï¼‰
db.orders.insertOne({
    _id: ObjectId("507f1f77bcf86cd799439011"),
    user: {
        id: 1001,
        name: "å¼ ä¸‰",
        email: "zhang@example.com"
    },
    total: 299.99,
    items: [
        {
            product_name: "æœºæ¢°é”®ç›˜",
            quantity:  1,
            price: 199.99
        },
        {
            product_name: "é¼ æ ‡å«",
            quantity: 2,
            price: 50.00
        }
    ],
    status: "completed",
    created_at: ISODate("2023-12-01T10:30:00Z")
});

// æŸ¥è¯¢æ— éœ€JOIN
db.orders.find({ "user.id": 1001 });
```

---

### 2. **CRUDæ“ä½œè¯¦è§£**

#### æ’å…¥æ•°æ®

```javascript
// æ’å…¥å•æ¡
db.products.insertOne({
    name: "iPhone 15",
    price: 5999,
    stock: 100,
    category: "æ‰‹æœº",
    specs: {
        screen: "6.1è‹±å¯¸",
        chip: "A17",
        storage: "128GB"
    },
    tags: ["5G", "åŒå¡", "Face ID"]
});

// æ’å…¥å¤šæ¡
db.products. insertMany([
    { name: "iPad", price: 3999, stock: 50 },
    { name: "MacBook", price: 9999, stock: 30 },
    { name: "AirPods", price: 1299, stock: 200 }
]);
```

#### æŸ¥è¯¢æ•°æ®

```javascript
// åŸºç¡€æŸ¥è¯¢
db.products. find({ category: "æ‰‹æœº" });

// æ¯”è¾ƒè¿ç®—ç¬¦
db.products.find({ price: { $gt: 5000 } });  // å¤§äº5000
db.products.find({ stock: { $gte: 50, $lte: 100 } });  // 50-100ä¹‹é—´
db.products.find({ category: { $in: ["æ‰‹æœº", "å¹³æ¿"] } });  // æ‰‹æœºæˆ–å¹³æ¿
db.products.find({ category: { $ne: "é…ä»¶" } });  // ä¸æ˜¯é…ä»¶

// é€»è¾‘è¿ç®—ç¬¦
db.products.find({
    $and: [
        { price: { $lt: 10000 } },
        { stock: { $gt: 0 } }
    ]
});

db.products.find({
    $or: [
        { category: "æ‰‹æœº" },
        { price: { $lt: 2000 } }
    ]
});

// åµŒå¥—æ–‡æ¡£æŸ¥è¯¢
db.products.find({ "specs.storage": "256GB" });

// æ•°ç»„æŸ¥è¯¢
db.products.find({ tags: "5G" });  // tagsæ•°ç»„åŒ…å«"5G"
db.products.find({ tags: { $all: ["5G", "åŒå¡"] } });  // åŒæ—¶åŒ…å«ä¸¤ä¸ªæ ‡ç­¾
db.products.find({ tags: { $size: 3 } });  // tagsæ•°ç»„é•¿åº¦ä¸º3

// æ­£åˆ™è¡¨è¾¾å¼
db.products. find({ name: /iPhone/i });  // ä¸åŒºåˆ†å¤§å°å†™

// æŠ•å½±ï¼ˆåªè¿”å›æŒ‡å®šå­—æ®µï¼‰
db.products.find(
    { category: "æ‰‹æœº" },
    { name: 1, price: 1, _id: 0 }  // 1=è¿”å›, 0=ä¸è¿”å›
);

// æ’åºã€åˆ†é¡µ
db.products.find({ category: "æ‰‹æœº" })
    .sort({ price: -1 })  // æŒ‰ä»·æ ¼é™åº
    .skip(10)             // è·³è¿‡10æ¡
    .limit(10);           // è¿”å›10æ¡
```

#### æ›´æ–°æ•°æ®

```javascript
// æ›´æ–°å•æ¡
db.products. updateOne(
    { name: "iPhone 15" },
    { $set: { price: 5799, stock: 95 } }
);

// æ›´æ–°å¤šæ¡
db.products.updateMany(
    { category: "æ‰‹æœº" },
    { $set: { on_sale: true } }
);

// æ›´æ–°è¿ç®—ç¬¦
db.products.updateOne(
    { name: "iPhone 15" },
    {
        $inc: { stock: -1 },              // åº“å­˜-1
        $set: { last_update: new Date() }, // è®¾ç½®å­—æ®µ
        $push: { tags: "çƒ­é”€" },          // æ•°ç»„æ·»åŠ å…ƒç´ 
        $addToSet: { tags: "æ–°å“" }       // æ•°ç»„æ·»åŠ ï¼ˆä¸é‡å¤ï¼‰
    }
);

// æ•°ç»„æ“ä½œ
db.products.updateOne(
    { name: "iPhone 15" },
    { $pull: { tags: "æ–°å“" } }  // ä»æ•°ç»„åˆ é™¤
);

db.products.updateOne(
    { name: "iPhone 15" },
    { $pop: { tags: 1 } }  // åˆ é™¤æ•°ç»„æœ€åä¸€ä¸ªå…ƒç´ ï¼ˆ-1åˆ é™¤ç¬¬ä¸€ä¸ªï¼‰
);

// upsertï¼ˆä¸å­˜åœ¨åˆ™æ’å…¥ï¼‰
db.products.updateOne(
    { name: "æ–°äº§å“" },
    { $set: { price: 999, stock: 100 } },
    { upsert: true }
);

// æ›¿æ¢æ•´ä¸ªæ–‡æ¡£
db.products. replaceOne(
    { name: "iPhone 15" },
    {
        name: "iPhone 15 Pro",
        price: 7999,
        stock: 50
    }
);
```

#### åˆ é™¤æ•°æ®

```javascript
// åˆ é™¤å•æ¡
db.products.deleteOne({ name: "iPhone 15" });

// åˆ é™¤å¤šæ¡
db.products.deleteMany({ stock: 0 });

// åˆ é™¤æ‰€æœ‰
db.products.deleteMany({});
```

---

### 3. **èšåˆç®¡é“ï¼ˆAggregationï¼‰**

```javascript
// åœºæ™¯ï¼šç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„å•†å“æ•°é‡å’Œå¹³å‡ä»·æ ¼
db.products. aggregate([
    // é˜¶æ®µ1ï¼šç­›é€‰
    { $match:  { stock: { $gt: 0 } } },
    
    // é˜¶æ®µ2ï¼šåˆ†ç»„
    {
        $group: {
            _id: "$category",
            count: { $sum: 1 },
            avgPrice: { $avg: "$price" },
            maxPrice: { $max: "$price" },
            minPrice: { $min: "$price" }
        }
    },
    
    // é˜¶æ®µ3ï¼šæ’åº
    { $sort: { count: -1 } },
    
    // é˜¶æ®µ4ï¼šé™åˆ¶ç»“æœ
    { $limit: 5 }
]);

// è¾“å‡ºï¼š
[
    { _id: "æ‰‹æœº", count: 15, avgPrice: 4500, maxPrice: 9999, minPrice: 1999 },
    { _id:  "å¹³æ¿", count: 10, avgPrice: 3500, maxPrice: 7999, minPrice: 2199 },
    ... 
]
```

#### å¤æ‚èšåˆç¤ºä¾‹

```javascript
// åœºæ™¯ï¼šè®¢å•ç»Ÿè®¡åˆ†æ
db.orders.aggregate([
    // 1. è§£æ„æ•°ç»„ï¼ˆæ¯ä¸ªitemå˜æˆä¸€æ¡è®°å½•ï¼‰
    { $unwind: "$items" },
    
    // 2. ç­›é€‰2023å¹´çš„è®¢å•
    {
        $match: {
            created_at: {
                $gte: ISODate("2023-01-01"),
                $lt: ISODate("2024-01-01")
            }
        }
    },
    
    // 3. è®¡ç®—æ¯ä¸ªå•†å“çš„é”€å”®é¢
    {
        $project: {
            product_name:  "$items.product_name",
            revenue: { $multiply: ["$items.quantity", "$items.price"] },
            month: { $month: "$created_at" }
        }
    },
    
    // 4. æŒ‰æœˆä»½å’Œå•†å“åˆ†ç»„
    {
        $group: {
            _id: {
                month: "$month",
                product:  "$product_name"
            },
            total_revenue: { $sum: "$revenue" },
            total_quantity: { $sum: "$items.quantity" }
        }
    },
    
    // 5. é‡æ–°ç»„ç»‡è¾“å‡º
    {
        $project: {
            _id: 0,
            month: "$_id.month",
            product: "$_id.product",
            revenue: "$total_revenue",
            quantity: "$total_quantity"
        }
    },
    
    // 6. æ’åº
    { $sort: { month: 1, revenue: -1 } }
]);
```

---

### 4. **ç´¢å¼•ä¼˜åŒ–**

```javascript
// åˆ›å»ºå•å­—æ®µç´¢å¼•
db.products. createIndex({ name: 1 });  // 1=å‡åº, -1=é™åº

// åˆ›å»ºå¤åˆç´¢å¼•
db.products. createIndex({ category: 1, price: -1 });

// åˆ›å»ºå”¯ä¸€ç´¢å¼•
db.users.createIndex({ email: 1 }, { unique: true });

// åˆ›å»ºæ–‡æœ¬ç´¢å¼•ï¼ˆå…¨æ–‡æœç´¢ï¼‰
db. articles.createIndex({ title: "text", content: "text" });
db.articles.find({ $text: { $search: "MongoDB æ•™ç¨‹" } });

// åˆ›å»ºTTLç´¢å¼•ï¼ˆè‡ªåŠ¨åˆ é™¤è¿‡æœŸæ•°æ®ï¼‰
db.sessions.createIndex(
    { created_at: 1 },
    { expireAfterSeconds: 3600 }  // 1å°æ—¶åè‡ªåŠ¨åˆ é™¤
);

// æŸ¥çœ‹ç´¢å¼•
db.products.getIndexes();

// åˆ é™¤ç´¢å¼•
db.products. dropIndex("name_1");

// åˆ†ææŸ¥è¯¢æ€§èƒ½
db.products. find({ category: "æ‰‹æœº" }).explain("executionStats");
```

---

### 5. **å‰¯æœ¬é›†ï¼ˆReplica Setï¼‰é«˜å¯ç”¨**

```mermaid
graph TB
    subgraph "MongoDBå‰¯æœ¬é›†"
        P[PrimaryèŠ‚ç‚¹<br/>ä¸»èŠ‚ç‚¹<br/>å¤„ç†æ‰€æœ‰å†™æ“ä½œ]
        S1[SecondaryèŠ‚ç‚¹1<br/>ä»èŠ‚ç‚¹<br/>åŒæ­¥æ•°æ®å¤‡ä»½]
        S2[SecondaryèŠ‚ç‚¹2<br/>ä»èŠ‚ç‚¹<br/>åŒæ­¥æ•°æ®å¤‡ä»½]
    end
    
    Client[åº”ç”¨ç¨‹åº] -->|å†™æ“ä½œ| P
    Client -->|è¯»æ“ä½œå¯é€‰| S1
    Client -->|è¯»æ“ä½œå¯é€‰| S2
    
    P -.->|åŒæ­¥Oplog| S1
    P -.->|åŒæ­¥Oplog| S2
    
    P -->|PrimaryæŒ‚äº†| X[é€‰ä¸¾]
    X -->|æå‡ä¸ºæ–°Primary| S1
    
    style P fill:#4caf50
    style S1 fill:#ffeb3b
    style S2 fill:#ffeb3b
```

#### å‰¯æœ¬é›†é…ç½®

```javascript
// åˆå§‹åŒ–å‰¯æœ¬é›†
rs.initiate({
    _id: "myReplicaSet",
    members: [
        { _id:  0, host: "mongo1:27017" },
        { _id: 1, host: "mongo2:27017" },
        { _id: 2, host: "mongo3:27017" }
    ]
});

// æŸ¥çœ‹å‰¯æœ¬é›†çŠ¶æ€
rs.status();

// æ·»åŠ èŠ‚ç‚¹
rs.add("mongo4:27017");

// è®¾ç½®ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå¤§è¶Šå®¹æ˜“æˆä¸ºPrimaryï¼‰
cfg = rs.conf();
cfg.members[1].priority = 2;
rs.reconfig(cfg);
```

#### Javaè¿æ¥å‰¯æœ¬é›†

```java
// Spring Booté…ç½®
spring: 
  data:
    mongodb:
      uri: mongodb://mongo1:27017,mongo2:27017,mongo3:27017/mydb? replicaSet=myReplicaSet&readPreference=secondaryPreferred

// ä»£ç ç¤ºä¾‹
@Autowired
private MongoTemplate mongoTemplate;

// å†™æ“ä½œï¼ˆè‡ªåŠ¨å‘é€åˆ°Primaryï¼‰
public void saveProduct(Product product) {
    mongoTemplate.save(product);
}

// è¯»æ“ä½œï¼ˆå¯ä»¥ä»Secondaryè¯»å–ï¼Œå‡è½»Primaryå‹åŠ›ï¼‰
@ReadPreference(ReadPreferenceType.SECONDARY_PREFERRED)
public List<Product> findProducts(String category) {
    Query query = new Query(Criteria. where("category").is(category));
    return mongoTemplate.find(query, Product.class);
}
```

---

### 6. **åˆ†ç‰‡é›†ç¾¤ï¼ˆShardingï¼‰æ°´å¹³æ‰©å±•**

```mermaid
graph TB
    subgraph "å®¢æˆ·ç«¯"
        App[åº”ç”¨ç¨‹åº]
    end
    
    subgraph "è·¯ç”±å±‚"
        Mongos1[Mongos<br/>è·¯ç”±æœåŠ¡1]
        Mongos2[Mongos<br/>è·¯ç”±æœåŠ¡2]
    end
    
    subgraph "é…ç½®æœåŠ¡å™¨"
        Config[Config Server<br/>å­˜å‚¨å…ƒæ•°æ®]
    end
    
    subgraph "åˆ†ç‰‡1 Shard1"
        S1P[Primary]
        S1S1[Secondary]
        S1S2[Secondary]
    end
    
    subgraph "åˆ†ç‰‡2 Shard2"
        S2P[Primary]
        S2S1[Secondary]
        S2S2[Secondary]
    end
    
    subgraph "åˆ†ç‰‡3 Shard3"
        S3P[Primary]
        S3S1[Secondary]
        S3S2[Secondary]
    end
    
    App --> Mongos1
    App --> Mongos2
    
    Mongos1 --> Config
    Mongos2 --> Config
    
    Mongos1 --> S1P
    Mongos1 --> S2P
    Mongos1 --> S3P
    
    S1P -.-> S1S1
    S1P -.-> S1S2
    S2P -.-> S2S1
    S2P -.-> S2S2
    S3P -.-> S3S1
    S3P -.-> S3S2
    
    style Mongos1 fill:#e1f5ff
    style Mongos2 fill:#e1f5ff
    style Config fill:#fff3e0
    style S1P fill:#4caf50
    style S2P fill:#4caf50
    style S3P fill:#4caf50
```

#### åˆ†ç‰‡ç­–ç•¥

```javascript
// 1. å¯ç”¨åˆ†ç‰‡
sh.enableSharding("mydb");

// 2. åˆ›å»ºåˆ†ç‰‡é”®ç´¢å¼•
db.products.createIndex({ category: 1, _id: 1 });

// 3. å¯¹é›†åˆè¿›è¡Œåˆ†ç‰‡
sh.shardCollection("mydb. products", { category: 1, _id: 1 });

// æ•°æ®åˆ†å¸ƒç¤ºä¾‹ï¼š
// Shard1: category = "æ‰‹æœº"
// Shard2: category = "å¹³æ¿"
// Shard3: category = "é…ä»¶"

// æŸ¥çœ‹åˆ†ç‰‡çŠ¶æ€
sh.status();
```

---

## å…­ã€Apollo é…ç½®ä¸­å¿ƒæ·±åº¦è§£æ

### 1. **æ ¸å¿ƒæ¦‚å¿µ**

```mermaid
graph LR
    subgraph "Apolloæ¶æ„"
        Portal[Portal<br/>ç®¡ç†ç•Œé¢]
        AdminService[Admin Service<br/>é…ç½®ç®¡ç†]
        ConfigService[Config Service<br/>é…ç½®è¯»å–]
        MetaServer[Meta Server<br/>æœåŠ¡å‘ç°]
    end
    
    subgraph "å­˜å‚¨"
        MySQL[(MySQL<br/>é…ç½®å­˜å‚¨)]
    end
    
    subgraph "åº”ç”¨ç«¯"
        Client[Javaåº”ç”¨<br/>Apollo Client]
    end
    
    Portal --> AdminService
    AdminService --> MySQL
    ConfigService --> MySQL
    Client --> ConfigService
    Client --> MetaServer
    
    style Portal fill:#e1f5ff
    style ConfigService fill:#e8f5e9
    style Client fill:#fff3e0
```

---

### 2. **é…ç½®ç®¡ç†å®æˆ˜**

#### åˆ›å»ºé…ç½®

```properties
# applicationå‘½åç©ºé—´ï¼ˆå…¬å…±é…ç½®ï¼‰
app.name=my-service
server.port=8080

# databaseå‘½åç©ºé—´ï¼ˆæ•°æ®åº“é…ç½®ï¼‰
spring.datasource.url=jdbc:mysql://localhost:3306/mydb
spring.datasource.username=root
spring.datasource. password=123456
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

# rediså‘½åç©ºé—´ï¼ˆRedisé…ç½®ï¼‰
spring.redis. host=localhost
spring.redis. port=6379
spring.redis.database=0
```

#### Javaé›†æˆ

```java
// 1. æ·»åŠ ä¾èµ–
<dependency>
    <groupId>com.ctrip.framework.apollo</groupId>
    <artifactId>apollo-client</artifactId>
    <version>2.0.1</version>
</dependency>

// 2. é…ç½®æ–‡ä»¶
# application.properties
app.id=my-service
apollo.meta=http://apollo-config-server:8080
apollo.bootstrap. enabled=true
apollo.bootstrap.namespaces=application,database,redis

// 3. å¯åŠ¨ç±»
@SpringBootApplication
@EnableApolloConfig
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}

// 4. ä½¿ç”¨é…ç½®
@Service
public class UserService {
    // æ–¹å¼1ï¼š@Valueæ³¨è§£
    @Value("${server.port:8080}")
    private int port;
    
    // æ–¹å¼2ï¼š@ConfigurationProperties
    @Autowired
    private DataSourceProperties dataSourceProperties;
    
    // æ–¹å¼3ï¼šç›‘å¬é…ç½®å˜åŒ–
    @ApolloConfigChangeListener
    public void onChange(ConfigChangeEvent changeEvent) {
        for (String key : changeEvent.changedKeys()) {
            ConfigChange change = changeEvent.getChange(key);
            log.info("é…ç½®å˜åŒ–: {} - æ—§å€¼: {}, æ–°å€¼: {}",
                key, change.getOldValue(), change.getNewValue());
            
            // æ ¹æ®é…ç½®å˜åŒ–æ‰§è¡Œä¸šåŠ¡é€»è¾‘
            if ("max. pool.size".equals(key)) {
                updateThreadPool(Integer.parseInt(change.getNewValue()));
            }
        }
    }
}

@ConfigurationProperties(prefix = "spring.datasource")
@Data
public class DataSourceProperties {
    private String url;
    private String username;
    private String password;
}
```

---

### 3. **ç°åº¦å‘å¸ƒ**

```mermaid
sequenceDiagram
    participant Admin as ç®¡ç†å‘˜
    participant Portal as Apollo Portal
    participant S1 as æœåŠ¡å®ä¾‹1<br/>ç°åº¦IP
    participant S2 as æœåŠ¡å®ä¾‹2
    participant S3 as æœåŠ¡å®ä¾‹3
    
    Admin->>Portal: 1. åˆ›å»ºç°åº¦è§„åˆ™<br/>IP=192.168.1.10
    Portal->>S1: 2. æ¨é€æ–°é…ç½®<br/>timeout=5000
    S1-->>Portal: 3. æ‹‰å–æˆåŠŸ
    
    Note over S1: ä½¿ç”¨æ–°é…ç½®<br/>timeout=5000
    Note over S2,S3: ä½¿ç”¨æ—§é…ç½®<br/>timeout=3000
    
    Admin->>Portal: 4. è§‚å¯Ÿç°åº¦æ•ˆæœ
    
    Admin->>Portal: 5. å…¨é‡å‘å¸ƒ
    Portal->>S2: 6. æ¨é€æ–°é…ç½®
    Portal->>S3: 6. æ¨é€æ–°é…ç½®
    
    Note over S1,S3: å…¨éƒ¨ä½¿ç”¨æ–°é…ç½®<br/>timeout=5000
```

**æ“ä½œæ­¥éª¤**ï¼š
1. Portalç•Œé¢ç‚¹å‡»"åˆ›å»ºç°åº¦"
2. è¾“å…¥ç°åº¦IPï¼š`192.168.1.10`
3. ä¿®æ”¹é…ç½®å€¼
4. ç‚¹å‡»"ç°åº¦å‘å¸ƒ"
5. è§‚å¯Ÿç°åº¦æœºå™¨çš„æ—¥å¿—å’Œç›‘æ§
6. ç¡®è®¤æ— é—®é¢˜åç‚¹å‡»"å…¨é‡å‘å¸ƒ"
7. æˆ–å‘ç°é—®é¢˜ç‚¹å‡»"æ”¾å¼ƒç°åº¦"

---

### 4. **å¤šç¯å¢ƒç®¡ç†**

```
é¡¹ç›®ç»“æ„ï¼š
my-service
  â”œâ”€â”€ DEVï¼ˆå¼€å‘ç¯å¢ƒï¼‰
  â”‚   â”œâ”€â”€ application
  â”‚   â”‚   â””â”€â”€ spring.profiles.active=dev
  â”‚   â””â”€â”€ database
  â”‚       â””â”€â”€ spring. datasource.url=jdbc:mysql://dev-db:3306/mydb
  â”‚
  â”œâ”€â”€ FATï¼ˆæµ‹è¯•ç¯å¢ƒï¼‰
  â”‚   â”œâ”€â”€ application
  â”‚   â”‚   â””â”€â”€ spring.profiles. active=fat
  â”‚   â””â”€â”€ database
  â”‚       â””â”€â”€ spring.datasource.url=jdbc:mysql://test-db:3306/mydb
  â”‚
  â””â”€â”€ PRODï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
      â”œâ”€â”€ application
      â”‚   â””â”€â”€ spring.profiles.active=prod
      â””â”€â”€ database
          â””â”€â”€ spring.datasource.url=jdbc:mysql://prod-db:3306/mydb
```

**é…ç½®æ–¹å¼**ï¼š
```bash
# å¼€å‘ç¯å¢ƒ
java -jar app.jar -Denv=DEV

# ç”Ÿäº§ç¯å¢ƒ
java -jar app.jar -Denv=PROD
```

---

## ä¸ƒã€Docker æ·±åº¦è§£æ

### 1. **Dockeræ ¸å¿ƒæ¦‚å¿µ**

```mermaid
graph TB
    subgraph "Dockeræ¶æ„"
        Client[Docker Client<br/>dockerå‘½ä»¤]
        Daemon[Docker Daemon<br/>dockerdå®ˆæŠ¤è¿›ç¨‹]
        Registry[Docker Registry<br/>é•œåƒä»“åº“]
    end
    
    subgraph "æœ¬åœ°èµ„æº"
        Images[Images<br/>é•œåƒ]
        Containers[Containers<br/>å®¹å™¨]
        Volumes[Volumes<br/>æ•°æ®å·]
        Networks[Networks<br/>ç½‘ç»œ]
    end
    
    Client -->|docker build| Daemon
    Client -->|docker run| Daemon
    Client -->|docker pull| Daemon
    
    Daemon -->|åˆ›å»º| Containers
    Daemon -->|æ‹‰å–| Registry
    Daemon -->|ç®¡ç†| Images
    Daemon -->|ç®¡ç†| Volumes
    Daemon -->|ç®¡ç†| Networks
    
    Images -->|å®ä¾‹åŒ–| Containers
    Volumes -->|æŒ‚è½½åˆ°| Containers
    Networks -->|è¿æ¥| Containers
    
    style Daemon fill:#4caf50
    style Containers fill:#2196f3
    style Images fill:#ff9800
```

---

### 2. **Dockerfile è¯¦è§£**

```dockerfile
# åŸºç¡€é•œåƒ
FROM openjdk:11-jre-slim

# ç»´æŠ¤è€…ä¿¡æ¯
LABEL maintainer="your-email@example.com"

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æ–‡ä»¶
COPY target/my-service.jar /app/app.jar

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV JAVA_OPTS="-Xms512m -Xmx1024m" \
    APP_ENV=prod \
    TZ=Asia/Shanghai

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --retries=3 \
    CMD curl -f http://localhost:8080/actuator/health || exit 1

# å¯åŠ¨å‘½ä»¤
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar /app/app.jar"]
```

#### å¤šé˜¶æ®µæ„å»ºï¼ˆå‡å°é•œåƒå¤§å°ï¼‰

```dockerfile
# é˜¶æ®µ1ï¼šæ„å»º
FROM maven:3.8-openjdk-11 AS builder
WORKDIR /build
COPY pom.xml . 
COPY src ./src
RUN mvn clean package -DskipTests

# é˜¶æ®µ2ï¼šè¿è¡Œ
FROM openjdk:11-jre-slim
WORKDIR /app
COPY --from=builder /build/target/*. jar app.jar
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "app.jar"]

# æœ€ç»ˆé•œåƒåªåŒ…å«JREå’ŒjaråŒ…ï¼Œä¸åŒ…å«Mavenå’Œæºä»£ç 
# é•œåƒå¤§å°ï¼šä»800MBé™åˆ°200MB
```

---

### 3. **æ„å»ºå’Œè¿è¡Œ**

```bash
# æ„å»ºé•œåƒ
docker build -t my-service:1.0.0 .

# æŸ¥çœ‹é•œåƒ
docker images

# è¿è¡Œå®¹å™¨
docker run -d \
    --name my-service \
    -p 8080:8080 \
    -e SPRING_PROFILES_ACTIVE=prod \
    -e JAVA_OPTS="-Xms512m -Xmx1024m" \
    -v /data/logs:/app/logs \
    --restart=always \
    my-service: 1.0.0

# å‚æ•°è¯´æ˜ï¼š
# -d:  åå°è¿è¡Œ
# --name:  å®¹å™¨åç§°
# -p: ç«¯å£æ˜ å°„ï¼ˆå®¿ä¸»æœº:å®¹å™¨ï¼‰
# -e: ç¯å¢ƒå˜é‡
# -v: æ•°æ®å·æŒ‚è½½ï¼ˆå®¿ä¸»æœº:å®¹å™¨ï¼‰
# --restart: é‡å¯ç­–ç•¥

# æŸ¥çœ‹è¿è¡Œä¸­çš„å®¹å™¨
docker ps

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs -f my-service

# è¿›å…¥å®¹å™¨
docker exec -it my-service /bin/bash

# åœæ­¢å®¹å™¨
docker stop my-service

# åˆ é™¤å®¹å™¨
docker rm my-service

# åˆ é™¤é•œåƒ
docker rmi my-service:1.0.0
```

---

### 4. **Docker ç½‘ç»œ**

```mermaid
graph TB
    subgraph "bridgeç½‘ç»œé»˜è®¤"
        C1[å®¹å™¨1<br/>172.17.0.2]
        C2[å®¹å™¨2<br/>172.17.0.3]
        Bridge[docker0ç½‘æ¡¥]
    end
    
    subgraph "è‡ªå®šä¹‰ç½‘ç»œ"
        C3[JavaæœåŠ¡<br/>my-network]
        C4[MySQL<br/>my-network]
        C5[Redis<br/>my-network]
    end
    
    C1 --> Bridge
    C2 --> Bridge
    Bridge --> Host[å®¿ä¸»æœº]
    
    C3 <--> C4
    C3 <--> C5
    C4 <--> C5
    
    style Bridge fill:#e3f2fd
    style C3 fill:#4caf50
    style C4 fill:#2196f3
    style C5 fill:#ff9800
```

```bash
# åˆ›å»ºè‡ªå®šä¹‰ç½‘ç»œ
docker network create my-network

# è¿è¡Œå®¹å™¨å¹¶åŠ å…¥ç½‘ç»œ
docker run -d --name mysql --network my-network \
    -e MYSQL_ROOT_PASSWORD=123456 \
    mysql:8.0

docker run -d --name redis --network my-network \
    redis:7.0

docker run -d --name my-service --network my-network \
    -p 8080:8080 \
    -e DB_HOST=mysql \
    -e REDIS_HOST=redis \
    my-service:1.0.0

# åœ¨my-serviceä¸­å¯ä»¥ç›´æ¥é€šè¿‡ä¸»æœºåè®¿é—®ï¼š
# jdbc:mysql://mysql:3306/mydb
# redis://redis:6379
```

---

### 5. **Docker Composeï¼ˆå®¹å™¨ç¼–æ’ï¼‰**

```yaml
# docker-compose.yml
version: '3.8'

services:
  # MySQLæœåŠ¡
  mysql:
    image: mysql:8.0
    container_name: my-mysql
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: mydb
      TZ: Asia/Shanghai
    ports:
      - "3306:3306"
    volumes: 
      - mysql-data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - backend
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 3

  # RedisæœåŠ¡
  redis:
    image: redis: 7.0-alpine
    container_name: my-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - backend
    command: redis-server --appendonly yes

  # MongoDBæœåŠ¡
  mongodb:
    image: mongo:6.0
    container_name: my-mongodb
    environment: 
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin123
    ports:
      - "27017:27017"
    volumes: 
      - mongo-data:/data/db
    networks:
      - backend

  # KafkaæœåŠ¡
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - backend

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment: 
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS:  PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks: 
      - backend

  # Javaåº”ç”¨æœåŠ¡
  app:
    build: 
      context: .
      dockerfile: Dockerfile
    image: my-service:latest
    container_name: my-service
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition:  service_started
      mongodb:
        condition:  service_started
      kafka:
        condition: service_started
    ports:
      - "8080:8080"
    environment:
      SPRING_PROFILES_ACTIVE:  prod
      DB_HOST: mysql
      DB_PORT: 3306
      REDIS_HOST: redis
      REDIS_PORT: 6379
      MONGO_HOST: mongodb
      MONGO_PORT: 27017
      KAFKA_SERVERS: kafka:9092
    volumes:
      - ./logs:/app/logs
    networks:
      - backend
    restart: unless-stopped

# æ•°æ®å·å®šä¹‰
volumes:
  mysql-data:
  redis-data: 
  mongo-data: 

# ç½‘ç»œå®šä¹‰
networks:
  backend: 
    driver: bridge
```

**ä½¿ç”¨æ–¹å¼**ï¼š
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f app

# åœæ­¢æ‰€æœ‰æœåŠ¡
docker-compose stop

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨
docker-compose down

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨å’Œæ•°æ®å·
docker-compose down -v

# é‡å¯å•ä¸ªæœåŠ¡
docker-compose restart app

# æ‰©å®¹ï¼ˆå¯åŠ¨å¤šä¸ªå®ä¾‹ï¼‰
docker-compose up -d --scale app=3
```

---

### 6. **æ•°æ®æŒä¹…åŒ–**

#### ä¸‰ç§æŒ‚è½½æ–¹å¼

```bash
# 1. Volumeï¼ˆæ¨èï¼‰- Dockerç®¡ç†
docker run -d --name mysql \
    -v mysql-data:/var/lib/mysql \
    mysql: 8.0

# æŸ¥çœ‹Volume
docker volume ls
docker volume inspect mysql-data

# 2. Bind Mount - æŒ‚è½½å®¿ä¸»æœºç›®å½•
docker run -d --name nginx \
    -v /home/user/html:/usr/share/nginx/html \
    nginx:alpine

# 3. tmpfs - ä¸´æ—¶æ–‡ä»¶ç³»ç»Ÿï¼ˆå†…å­˜ï¼‰
docker run -d --name app \
    --tmpfs /tmp \
    my-service:1.0.0
```

---

### 7. **æœ€ä½³å®è·µ**

#### ä¼˜åŒ–é•œåƒå¤§å°

```dockerfile
# âŒ ä¸å¥½çš„åšæ³•
FROM ubuntu:latest
RUN apt-get update
RUN apt-get install -y openjdk-11-jdk
RUN apt-get install -y maven
COPY .  /app
RUN cd /app && mvn package
CMD ["java", "-jar", "/app/target/app.jar"]
# é•œåƒå¤§å°ï¼š1.2GB

# âœ… å¥½çš„åšæ³•
FROM openjdk:11-jre-slim
COPY target/app.jar /app. jar
CMD ["java", "-jar", "/app.jar"]
# é•œåƒå¤§å°ï¼š200MB

# âœ… æ›´å¥½çš„åšæ³•ï¼ˆå¤šé˜¶æ®µæ„å»ºï¼‰
FROM maven:3.8-openjdk-11 AS build
WORKDIR /app
COPY pom.xml . 
COPY src ./src
RUN mvn package -DskipTests

FROM openjdk:11-jre-slim
COPY --from=build /app/target/app.jar /app.jar
CMD ["java", "-jar", "/app.jar"]
# é•œåƒå¤§å°ï¼š200MBï¼Œä¸”æ„å»ºè¿‡ç¨‹æ ‡å‡†åŒ–
```

#### åˆå¹¶RUNæŒ‡ä»¤

```dockerfile
# âŒ æ¯ä¸ªRUNåˆ›å»ºä¸€ä¸ªé•œåƒå±‚
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y vim
RUN rm -rf /var/lib/apt/lists/*

# âœ… åˆå¹¶ä¸ºä¸€ä¸ªRUN
RUN apt-get update \
    && apt-get install -y curl vim \
    && rm -rf /var/lib/apt/lists/*
```

#### ä½¿ç”¨. dockerignore

```bash
# . dockerignore
target/
. git/
.idea/
*.md
Dockerfile
docker-compose.yml
```

---

## å…«ã€ç³»ç»Ÿç›‘æ§ä¸è¿ç»´

### 1. **æ—¥å¿—æ”¶é›†æ¶æ„**

```mermaid
graph LR
    subgraph "åº”ç”¨å±‚"
        App1[JavaæœåŠ¡1]
        App2[JavaæœåŠ¡2]
        App3[JavaæœåŠ¡N]
    end
    
    subgraph "æ—¥å¿—æ”¶é›†"
        Filebeat[Filebeat<br/>æ—¥å¿—é‡‡é›†]
        Kafka[Kafka<br/>æ¶ˆæ¯é˜Ÿåˆ—]
    end
    
    subgraph "æ—¥å¿—å¤„ç†"
        Logstash[Logstash<br/>æ—¥å¿—è§£æ]
    end
    
    subgraph "å­˜å‚¨æŸ¥è¯¢"
        ES[Elasticsearch<br/>æ—¥å¿—å­˜å‚¨]
        Kibana[Kibana<br/>æ—¥å¿—æŸ¥è¯¢ç•Œé¢]
    end
    
    App1 -->|å†™æ—¥å¿—æ–‡ä»¶| Filebeat
    App2 -->|å†™æ—¥å¿—æ–‡ä»¶| Filebeat
    App3 -->|å†™æ—¥å¿—æ–‡ä»¶| Filebeat
    
    Filebeat --> Kafka
    Kafka --> Logstash
    Logstash --> ES
    ES --> Kibana
    
    style Kafka fill:#fff3e0
    style ES fill:#e8f5e9
    style Kibana fill:#e1f5ff
```

#### Logbacké…ç½®ï¼ˆè¾“å‡ºåˆ°æ–‡ä»¶ï¼‰

```xml
<!-- logback-spring.xml -->
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- æ§åˆ¶å°è¾“å‡º -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss. SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- æ–‡ä»¶è¾“å‡º -->
    <appender name="FILE" class="ch.qos. logback.core.rolling.RollingFileAppender">
        <file>/app/logs/app.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- æ¯å¤©ç”Ÿæˆä¸€ä¸ªæ—¥å¿—æ–‡ä»¶ -->
            <fileNamePattern>/app/logs/app. %d{yyyy-MM-dd}.log</fileNamePattern>
            <!-- ä¿ç•™30å¤© -->
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <!-- JSONæ ¼å¼ï¼Œæ–¹ä¾¿ELKè§£æ -->
            <pattern>{"time": "%d{yyyy-MM-dd HH:mm:ss.SSS}","level":"%level","thread":"%thread","class":"%logger{40}","message":"%msg"}%n</pattern>
        </encoder>
    </appender>
    
    <!-- Kafkaè¾“å‡ºï¼ˆç›´æ¥å‘é€åˆ°Kafkaï¼‰ -->
    <appender name="KAFKA" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>{"time":"%d{yyyy-MM-dd HH:mm:ss. SSS}","level":"%level","message":"%msg"}%n</pattern>
        </encoder>
        <topic>app-logs</topic>
        <keyingStrategy class="com.github.danielwegener. logback.kafka.keying.NoKeyKeyingStrategy"/>
        <deliveryStrategy class="com.github.danielwegener.logback.kafka. delivery.AsynchronousDeliveryStrategy"/>
        <producerConfig>bootstrap.servers=kafka:9092</producerConfig>
    </appender>
    
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="FILE"/>
        <appender-ref ref="KAFKA"/>
    </root>
</configuration>
```

---

### 2. **ç›‘æ§ä½“ç³»**

```mermaid
graph TB
    subgraph "åº”ç”¨å±‚"
        App[Javaåº”ç”¨<br/>æš´éœ²Metricsæ¥å£]
    end
    
    subgraph "æ•°æ®é‡‡é›†"
        Prometheus[Prometheus<br/>æ—¶åºæ•°æ®åº“]
    end
    
    subgraph "å¯è§†åŒ–"
        Grafana[Grafana<br/>ç›‘æ§å¤§ç›˜]
    end
    
    subgraph "å‘Šè­¦"
        AlertManager[AlertManager<br/>å‘Šè­¦ç®¡ç†]
        Email[é‚®ä»¶]
        SMS[çŸ­ä¿¡]
        Webhook[é’‰é’‰/ä¼å¾®]
    end
    
    App -->|/actuator/prometheus| Prometheus
    Prometheus -->|æŸ¥è¯¢æ•°æ®| Grafana
    Prometheus -->|è§¦å‘å‘Šè­¦| AlertManager
    AlertManager --> Email
    AlertManager --> SMS
    AlertManager --> Webhook
    
    style Prometheus fill:#ff9800
    style Grafana fill:#2196f3
    style AlertManager fill:#f44336
```

#### Spring Boot Actuatoré›†æˆ

```xml
<!-- pom.xml -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

```yaml
# application.yml
management:
  endpoints:
    web: 
      exposure:
        include:  health,info,prometheus,metrics
  metrics:
    tags:
      application:  ${spring.application.name}
    export:
      prometheus:
        enabled: true
```

#### è‡ªå®šä¹‰æŒ‡æ ‡

```java
@Component
public class CustomMetrics {
    private final MeterRegistry meterRegistry;
    
    public CustomMetrics(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
    }
    
    // è®¡æ•°å™¨ï¼ˆç´¯è®¡å€¼ï¼‰
    public void recordOrder() {
        meterRegistry.counter("order.created", "status", "success").increment();
    }
    
    // è®¡æ—¶å™¨ï¼ˆç»Ÿè®¡è€—æ—¶ï¼‰
    public void recordApiDuration(String api, long duration) {
        meterRegistry.timer("api.duration", "path", api)
            .record(duration, TimeUnit.MILLISECONDS);
    }
    
    // ä»ªè¡¨ç›˜ï¼ˆå½“å‰å€¼ï¼‰
    @PostConstruct
    public void init() {
        meterRegistry.gauge("thread.pool.active", threadPoolExecutor, ThreadPoolExecutor::getActiveCount);
    }
}

// ä½¿ç”¨ç¤ºä¾‹
@Service
public class OrderService {
    @Autowired
    private CustomMetrics customMetrics;
    
    public void createOrder(Order order) {
        long start = System.currentTimeMillis();
        
        try {
            // ä¸šåŠ¡é€»è¾‘
            orderDao.save(order);
            
            // è®°å½•æˆåŠŸ
            customMetrics.recordOrder();
        } finally {
            // è®°å½•è€—æ—¶
            customMetrics.recordApiDuration("/api/order/create", 
                System.currentTimeMillis() - start);
        }
    }
}
```

#### Prometheusé…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s  # æ¯15ç§’é‡‡é›†ä¸€æ¬¡

scrape_configs:
  # é‡‡é›†Javaåº”ç”¨
  - job_name: 'my-service'
    metrics_path: '/actuator/prometheus'
    static_configs: 
      - targets: ['my-service:8080']
  
  # é‡‡é›†MySQL
  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']
  
  # é‡‡é›†Redis
  - job_name: 'redis'
    static_configs: 
      - targets: ['redis-exporter:9121']
```

#### Grafana Dashboardé…ç½®

**å¸¸è§ç›‘æ§æŒ‡æ ‡**ï¼š
```promql
# JVMå†…å­˜ä½¿ç”¨ç‡
jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"} * 100

# CPUä½¿ç”¨ç‡
process_cpu_usage * 100

# QPSï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰
rate(http_server_requests_seconds_count[1m])

# æ¥å£å¹³å‡å“åº”æ—¶é—´
rate(http_server_requests_seconds_sum[1m]) / rate(http_server_requests_seconds_count[1m])

# é”™è¯¯ç‡
rate(http_server_requests_seconds_count{status=~"5.."}[1m]) / rate(http_server_requests_seconds_count[1m]) * 100

# çº¿ç¨‹æ± é˜Ÿåˆ—å¤§å°
thread_pool_queue_size

# æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡
hikaricp_connections_active / hikaricp_connections_max * 100
```

---

### 3. **å‘Šè­¦è§„åˆ™**

```yaml
# alert_rules.yml
groups:
  - name: application_alerts
    interval: 30s
    rules:
      # CPUä½¿ç”¨ç‡è¶…è¿‡80%
      - alert:  HighCPUUsage
        expr: process_cpu_usage * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "{{ $labels.instance }} CPUä½¿ç”¨ç‡ {{ $value }}%"
      
      # å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡85%
      - alert: HighMemoryUsage
        expr:  jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"} * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations: 
          summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
      
      # æ¥å£é”™è¯¯ç‡è¶…è¿‡5%
      - alert: HighErrorRate
        expr: rate(http_server_requests_seconds_count{status=~"5.."}[5m]) / rate(http_server_requests_seconds_count[5m]) * 100 > 5
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "æ¥å£é”™è¯¯ç‡è¿‡é«˜"
          description: "é”™è¯¯ç‡ {{ $value }}%"
      
      # æœåŠ¡å®•æœº
      - alert: ServiceDown
        expr: up{job="my-service"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æœåŠ¡å®•æœº"
          description: "{{ $labels.instance }} å·²å®•æœºè¶…è¿‡1åˆ†é’Ÿ"
```

---

### 4. **é“¾è·¯è¿½è¸ªï¼ˆåˆ†å¸ƒå¼è¿½è¸ªï¼‰**

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Gateway as APIç½‘å…³<br/>TraceID: abc123
    participant OrderService as è®¢å•æœåŠ¡<br/>SpanID:001
    participant InventoryService as åº“å­˜æœåŠ¡<br/>SpanID:002
    participant PaymentService as æ”¯ä»˜æœåŠ¡<br/>SpanID:003
    participant DB as æ•°æ®åº“
    
    User->>Gateway:  ä¸‹å•è¯·æ±‚
    Note over Gateway: ç”ŸæˆTraceID:  abc123
    
    Gateway->>OrderService: åˆ›å»ºè®¢å•<br/>TraceID:  abc123, SpanID:  001
    OrderService->>InventoryService: æ£€æŸ¥åº“å­˜<br/>TraceID: abc123, SpanID:  002, ParentID: 001
    InventoryService->>DB: æŸ¥è¯¢åº“å­˜
    DB-->>InventoryService: è¿”å›ç»“æœ
    InventoryService-->>OrderService: åº“å­˜å……è¶³
    
    OrderService->>PaymentService: æ‰£æ¬¾<br/>TraceID: abc123, SpanID:  003, ParentID: 001
    PaymentService->>DB: æ‰£å‡ä½™é¢
    DB-->>PaymentService:  æ‰£æ¬¾æˆåŠŸ
    PaymentService-->>OrderService: æ”¯ä»˜å®Œæˆ
    
    OrderService-->>Gateway: è®¢å•åˆ›å»ºæˆåŠŸ
    Gateway-->>User: è¿”å›ç»“æœ
```

#### Spring Cloud Sleuth + Zipkin

```xml
<!-- pom.xml -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework. cloud</groupId>
    <artifactId>spring-cloud-sleuth-zipkin</artifactId>
</dependency>
```

```yaml
# application.yml
spring:
  sleuth:
    sampler:
      probability: 1.0  # é‡‡æ ·ç‡100%ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®0.1ï¼‰
  zipkin:
    base-url: http://zipkin-server:9411
    sender:
      type: web
```

**æŸ¥çœ‹é“¾è·¯**ï¼š
- è®¿é—® `http://zipkin-server:9411`
- è¾“å…¥ TraceID æŸ¥çœ‹å®Œæ•´è°ƒç”¨é“¾
- å¯ä»¥çœ‹åˆ°æ¯ä¸ªæœåŠ¡çš„è€—æ—¶ã€æ˜¯å¦å‡ºé”™

---

### 5. **å¥åº·æ£€æŸ¥**

```java
// è‡ªå®šä¹‰å¥åº·æ£€æŸ¥
@Component
public class CustomHealthIndicator implements HealthIndicator {
    @Autowired
    private RedisTemplate redisTemplate;
    
    @Autowired
    private KafkaTemplate kafkaTemplate;
    
    @Override
    public Health health() {
        // æ£€æŸ¥Redisè¿æ¥
        try {
            redisTemplate.opsForValue().get("health-check");
        } catch (Exception e) {
            return Health.down()
                .withDetail("redis", "è¿æ¥å¤±è´¥:  " + e.getMessage())
                .build();
        }
        
        // æ£€æŸ¥Kafkaè¿æ¥
        // ... 
        
        // æ£€æŸ¥æ•°æ®åº“è¿æ¥æ± 
        HikariDataSource dataSource = getDataSource();
        int activeConnections = dataSource.getHikariPoolMXBean().getActiveConnections();
        int maxConnections = dataSource.getMaximumPoolSize();
        
        if (activeConnections > maxConnections * 0.9) {
            return Health.down()
                .withDetail("database", "è¿æ¥æ± å³å°†è€—å°½")
                .withDetail("active", activeConnections)
                .withDetail("max", maxConnections)
                .build();
        }
        
        return Health. up()
            .withDetail("redis", "æ­£å¸¸")
            .withDetail("kafka", "æ­£å¸¸")
            .withDetail("database", "æ­£å¸¸")
            .build();
    }
}
```

**è®¿é—®å¥åº·æ£€æŸ¥æ¥å£**ï¼š
```bash
curl http://localhost:8080/actuator/health

# è¿”å›ï¼š
{
  "status": "UP",
  "components": {
    "custom": {
      "status": "UP",
      "details": {
        "redis": "æ­£å¸¸",
        "kafka": "æ­£å¸¸",
        "database": "æ­£å¸¸"
      }
    },
    "diskSpace": {
      "status":  "UP",
      "details":  {
        "total": 500000000000,
        "free": 200000000000
      }
    }
  }
}
```

---

### 6. **å®Œæ•´çš„Docker Composeè¿ç»´é…ç½®**

```yaml
version: '3.8'

services:
  # åº”ç”¨æœåŠ¡
  app:
    image: my-service:latest
    deploy:
      replicas: 3  # 3ä¸ªå®ä¾‹
      resources: 
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval:  30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    environment:
      JAVA_OPTS: "-Xms1g -Xmx2g -XX:+UseG1GC"
  
  # Prometheus
  prometheus:
    image: prom/prometheus: latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config. file=/etc/prometheus/prometheus. yml'
      - '--storage. tsdb.path=/prometheus'
  
  # Grafana
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin123
  
  # Zipkin
  zipkin:
    image: openzipkin/zipkin:latest
    ports: 
      - "9411:9411"
  
  # Filebeat
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.10.0
    volumes:
      - ./filebeat. yml:/usr/share/filebeat/filebeat.yml
      - /var/lib/docker/containers:/var/lib/docker/containers: ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - kafka

volumes:
  prometheus-data: 
  grafana-data: 
```

---
